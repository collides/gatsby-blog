---
title: Redis 总结
date: 2020-07-01
update: 2020-07-20
tags: 数据库
---

1. 一个 K/V 数据库包含什么？

   - 访问模块
     - 动态库访问（动态链接库）
     - 网络访问框架
       - Socket Server
       - 请求解析

   - 数据结构 / 操作模块

     - 字符串
     - 数组
     - 链表
     - List
     - Hash

   - 索引模块

     索引类型有很多，常见的有哈希表、B tree 、字典树，不同的索引结构在性能、空间消耗、并发控制等方面具有不同特征

   - 存储模块

     - 分配器
     - 持久化

2. Redis 怎么避免数据丢失

   Redis 避免丢失其中一种方式是采用 AOF (日志)，Redis 会在写指令操作成功后对指令进行记录，格式为指令

   ![img](https://static001.geekbang.org/resource/image/4d/9f/4d120bee623642e75fdf1c0700623a9f.jpg)

   

   操作成功后记录日志不会阻塞指令的执行，但是会影响下一个指令的执行效率，还有一种可能指令操作成功后还没来得及写日志就发生了宕机导致数据丢失，对于这个问题 Redis 提供了三种写回 appendfsync 的参数

   ![img](https://static001.geekbang.org/resource/image/72/f8/72f547f18dbac788c7d11yy167d7ebf8.jpg)

   

   如果日志文件太大了怎么办，Redis 提供了重写机制简单来说，根据当前数据库现状创建一个新的 AOF 文件

   并通过只记录当前数据库最新状态的优化方案进行记录

   ![img](https://static001.geekbang.org/resource/image/65/08/6528c699fdcf40b404af57040bb8d208.jpg)

   什么时候会触发 AOF 重写，

   - 手动触发 `bgrewriteaof`
   - 自动触发 通过 config 指定相应参数
     - auto-aof-rewrite-percentage 100  // 比上次重写后的体量增加了100%
     - auto-aof-rewrite-min-size 64mb // 文件大于 64 MB

   AOF 重写会阻塞线程吗？不会，当发生重写时 Redis 会 fork 出一个 bgrewriteaof 子进程，将主进程的内存页表即虚拟内存与实际内存的映射关系 Copy 到子进程，就可以不阻塞主线程的情况下将数据写入到新的 AOF，

   如果有增量数据进入，主进程会继续将日志写入相应内存缓冲区即写旧文件，并且也会写入到新AOF重写缓冲区
   
3. RDB 机制

   Redis 支持将当前数据状态打一份内存快照保存到磁盘中，RDB 是全量内存快照相比较 AOF 恢复数据时需要执行全部的操作指令性能较差而`RDB存储的是压缩后的二进制文件，文件较小，对不同的数据类型有针对性的优化，可以通过解析还原数据`，RDB 不会阻塞主线程因为在执行 RDB 时会 fork 出一个子进程进行执行，但是 fork 的过程还是会阻塞主线程，在做快照的中途如果主线程发生了读操作不会影响执行但是如果写数据会将数据做一份副本，RDB 将写入副本 主线程写入数据

   ![img](https://static001.geekbang.org/resource/image/a2/58/a2e5a3571e200cb771ed8a1cd14d5558.jpg)

   

   关于快照的频率不宜过于频繁虽然子进程不会阻塞主线程，但是 fork 的过程还是会阻塞主线程 而且还会产生其他功耗，但是如果频率过慢就可能发生数据丢失，Redis 4.0 中提出了一个混合使用 AOF 和 RDB 的方法，
   
   内存快照在一定时间内执行，将两个快照中间的增量数据操作写入 AOF，即减少了快照开销又节省了 AOF 存储指令数量
   
   ![img](https://static001.geekbang.org/resource/image/e4/20/e4c5846616c19fe03dbf528437beb320.jpg)
   
4. 主从库如何实现数据

   redis 主从机制采用了读写分离，主库负责接收读写请求，从库负责接收读请求，为保证从库可以正确的响应读请求，主库需要向从库同步数据

   - 亮点1：Redis采用读写分离的好处：避免了加锁，实例间协商是否完成修改等复杂操作
   - 亮点2：全量同步的发生时机：首次上线 和 从库的环形缓冲区位置标识被覆盖

   - 亮点3：增量同步保障机制依赖于一个特殊的数据结构：环形缓冲区

   - 要点1：首次同步分为三个阶段，①：建立连接，②：同步RDB文件，③：同步增量数据

   - 要点2：全量同步需要主机fork子进程，产生全量RDB文件，并发送，为了减轻主机的压力，从机之间也可用互相同步

   - 要点3：增量同步可以缓解主机全量同步的压力，它需要特殊机制保障：replication buffer，环形缓冲区，master_repl_offset，slave_repl_offset

   - 要点4：从机的同步位置标识，在环形缓冲区被覆盖后，会触发新的一轮全量同步，所repl_backlog_buffer的大小是redis重要的调优参数

   - 要点5：主从同步有三种机制：全量同步，基于长链接的命令传播（在写这个笔记时把它忽略了），增量同步

   - 1，repl_backlog_buffer，是随着主机一起诞生的
   - 2，主机和所有的clent端（包括从机）都会建立一个对应的buffer
   - 3，replication buffer是与每个clent端一一对应
   - 4，redis的所有写命令除了用于长链接广播，还都会写入repl_backlog_buffer

5. 哨兵机制

   哨兵机制提供了三种方式来做主库高可用

   - 周期性监听主从库，判断是否下线
   - 下线后进行选举主库并切换
   - 切换成功后发送通知到客户端和从库

   1.周期性的向主从库发送 `ping` 网络请求，如果目的地端恢复`ping` 则证明目的地为上线状态否则标为下线状态，下线状态分 `主观下线` 和 `客观下线` 两种，因为网络通信的不可靠性可能会存在网络拥塞或者目的地端网络压力较大会出现`误判`，为了解决该问题可以部署多个哨兵即哨兵集群，各个烧饼会分别对主库进行网络请求判定是否主观下线 当多数时判定为客观下线进行选举主库

   2.主库选举首先会过滤一遍网络较差的从库 具体怎么判断呢？使用配置项 down-after-milliseconds * 10。其中，down-after-milliseconds 是我们认定主从库断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库，后就可以进行打分选举了可以分为三个阶段：从库优先级、从库复制进度、从库 id 长度。

   - 从库优先级

     用户可以通过 `slave-priority` 配置来提升配置较好的从库，如果没有较高优先级的从库即进入下一个阶段。

   - 从库复制进度

     从库通过 `slave-repl-offset` 进行对比选举最接近 `master-repl-offset` 的从库，如果没有最接近的即进入下一个阶段。

   - 从库 id 长度

     redis 默认规则为选举实例 id 较短的从库。

     我们再回顾下这个流程。首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符合要求的从库，然后，依次按照优先级、复制进度、ID 号大小再对剩余的从库进行打分，只要有得分最高的从库出现，就把它选为新主库。
   
   哨兵的运行机制
   
   哨兵怎么订阅其他哨兵并组成一个哨兵集群，redis 提供了 pub/sub 的机制，可以向主库建立通信并区分事件类型 如`__sentinel__:hello` 的管道，哨兵可以通过该管道发布自己的 ip、port、id、和订阅该管道消息获取其他哨兵信息并建立连接
   
   ![img](https://static001.geekbang.org/resource/image/ca/b1/ca42698128aa4c8a374efbc575ea22b1.jpg)
   
   哨兵怎么和从库建立连接呢这是由哨兵向主库发送 `INFO` 指令获取从库列表建立连接
   
   ![img](https://static001.geekbang.org/resource/image/88/e0/88fdc68eb94c44efbdf7357260091de0.jpg)
   
   哨兵怎么和客户端传递消息呢，也是通过主库 pub/sub 的机制客户端通过订阅不同的管道获取不同的信息
   
   ![img](https://static001.geekbang.org/resource/image/4e/25/4e9665694a9565abbce1a63cf111f725.jpg)
   
   哨兵是怎么选举出 leader 呢，首先哨兵会判定是否为`客观下线`
   
   ![img](https://static001.geekbang.org/resource/image/e0/84/e0832d432c14c98066a94e0ef86af384.jpg)
   
   后会进行 leader 选举，机制如下
   
   ![img](https://static001.geekbang.org/resource/image/5f/d9/5f6ceeb9337e158cc759e23c0f375fd9.jpg)
   
6. 集群方案

   如果数据量很大，有两种解决方案

   - 纵向扩容

     就是增加机器的性能提升内存 cpu 磁盘大小，优点是扩容简单容易，缺点是成本大，数据量大时 RDB fork 比较耗时

   - 横向扩容

     就是增加机器节点组成一个`切片集群`，优点是扩容成本低，缺点是切片集群比较复杂

   什么是切片集群，切片集群会将数据以切片的方式存入各个节点，但是数据是怎么分布的和寻址的呢，

   实际上，切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在 Redis 3.0 之前，官方并没有针对切片集群提供具体的方案。从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则。Redis Cluster 采用哈希槽（Hash Slot）来处理数据与节点之间的关系，一个切片集群有 `16384` 个哈希槽，这些哈希槽类似于数据分区，每个键值都会根据它的 key，被映射到一个哈希槽, 

   首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽

   ![img](https://static001.geekbang.org/resource/image/7d/ab/7d070c8b19730b308bfaabbe82c2f1ab.jpg)

   也可以通过手动指定哈希槽分布

   ```bash
   redis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1
   redis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3
   redis-cli -h 172.16.19.5 –p 6379 cluster addslots 4
   ```

   注意：在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。

   客户端如何确定要访问那个实例获取数据：1从任意个实例获取并缓存在自己本地，2，重定向机制

   重定向机制：客户端访问的实例没有数据，被访问实例响应move命令，告诉客户端指向新的实例地址

   ASK命令：1，表明数据正在迁移 ；2，告知客户端数据所在的实例
   ASK命令和MOVE命令的区别：
         	move命令是在数据迁移完毕后被响应，客户端会更新本地缓存。
             ASK命令是在数据迁移中被响应，不会让客户端更新缓存
   
7. String 处理

   一，作者讲了什么？
     Redis的String类型数据结构，及其底层实现
   二，作者是怎么把这事给说明白的？
     1，通过一个图片存储的案例，讲通过合理利用Redis的数据结构，降低资源消耗

   三，为了讲明白，作者讲了哪些要点？有哪些亮点？
   1，亮点1：String类型的数据占用内存，分别是被谁占用了
   2，亮点2：可以巧妙的利用Redis的底层数据结构特性，降低资源消耗
   3，要点1： Simple Dynamic String结构体（
            buf：字节数组，为了表示字节结束，会在结尾增加“\0”
            len： 占4个字节，表示buf的已用长度
            alloc：占4个字节，表示buf实际分配的长度，一般大于len）

   4，要点2： RedisObject 结构体（
             元数据：8字节（用于记录最后一次访问时间，被引用次数。。。）
             指针：8字节，指向具体数据类型的实际数据所在 ）

   5，要点3：dicEntry 结构体（
            key：8个字节指针，指向key
            value：8个字节指针，指向value
            next：指向下一个dicEntry）
   6，要点4：ziplist(压缩列表)（
            zlbytes：在表头，表示列表长度
            zltail：在表头，表示列尾偏移量
            zllen：在表头，表示列表中
            entry：保存数据对象模型
            zlend：在表尾，表示列表结束）
   entry：（
          prev_len：表示一个entry的长度，有两种取值方式：1字节或5字节。
              1字节表示一个entry小于254字节，255是zlend的默认值，所以不使用。
          len：表示自身长度，4字节
          encodeing：表示编码方式，1字节
          content：保存实际数据）

   5，要点4：String类型的内存空间消耗
   ①，保存Long类型时，指针直接保存整数数据值，可以节省空间开销（被称为：int编码）
   ②，保存字符串，且不大于44字节时，RedisObject的元数据，指针和SDS是连续的，可以避免内存碎片（被称为：embstr编码）
   ③，当保存的字符串大于44字节时，SDS的数据量变多，Redis会给SDS分配独立的空间，并用指针指向SDS结构（被称为：raw编码）
   ④，Redis使用一个全局哈希表保存所以键值对，哈希表的每一项都是一个dicEntry，每个dicEntry占用32字节空间
   ⑤，dicEntry自身24字节，但会占用32字节空间，是因为Redis使用了内存分配库jemalloc。
             jemalloc在分配内存时，会根据申请的字节数N，找一个比N大，但最接近N的2的幂次数作为分配空间，这样可以减少频繁分配内存的次数

   4，要点5：使用什么数据结构可以节省内存？
   ①， 压缩列表，是一种非常节省内存的数据结构，因为他使用连续的内存空间保存数据，不需要额外的指针进行连接
   ②，Redis基于压缩列表实现List，Hash，Sorted Set集合类型，最大的好处是节省了dicEntry开销

   5，要点6：如何使用集合类型保存键值对？
   ①，Hash类型设置了用压缩列表保存数据时的两个阀值，一旦超过就会将压缩列表转为哈希表，且不可回退
   ②，hash-max-ziplist-entries：表示用压缩列表保存哈希集合中的最大元素个数
   ③，hash-max-ziplist-value：表示用压缩列表保存时，哈希集合中单个元素的最大长度

   四，对于作者所讲，我有哪些发散性思考？
     看了老师讲解，做了笔记，又看了黄建宏写的《Redis 设计与实现》
   有这样的讲解：
       当哈希对象可以同时满足以下两个条件时， 哈希对象使用 ziplist 编码：
   \1. 哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节；
   \2. 哈希对象保存的键值对数量小于 512 个；

8. 统计相关

   - 聚合统计

     案例1. 交集统计

     ​		在记录用户流存量，使用 set 进行记录，用一个 key 记录所有用户，再用另外一个 key 记录每日登录用户，我们只用计算每日用户 Set 和累计用户 Set 的差集就行

     ![img](https://static001.geekbang.org/resource/image/a6/9e/a63dd95d5e44bf538fe960e67761b59e.jpg)

     注意：在数据量很大的情况下取 set 类型交、差、并集的时候可能会阻塞 redis 实例

   - 排序统计

     案例：记录商品用户评论，可以使用 List 来记录因为 List 本身是按下标进行位移排序的每次新增数据将数据 PUSH 到 List 顶部，但是如果是分页的情况下如果新增一条新数据会引发数据错位导致取值数据不一致，可以采用 Sorted List 来保存数据，Sorted List 是按照某一个属性权重进行排序，按照某一个 range 就可以保证数据一致

   - 二值状态统计

     案例：记录用户签到，可以使用 BitMap 来保存数据，BitMap 是用 bit 顺序存放的只有 `0|1` ，BitMap 底层是使用 String 实现的会保存成一个二进制字节数组，BitMap 提供了 COUNT 方法可以很容易记录用户签到量，在统计连续签到时可以采用 BitMap 的按为与操作进行简化数据，将每天签到的 BitMap 按为与后取 1 的数量

   - 基数统计

     案例：记录网页 UV，可以采用 HyperLogLog 来进行记录，HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小

   ![img](https://static001.geekbang.org/resource/image/c0/6e/c0bb35d0d91a62ef4ca1bd939a9b136e.jpg)
   
9. 消息队列

   消息队列三个问题，数据时序性、数据重复、数据可靠性

   Redis 有两种方式做消息队列的方式

   - List

     生产者 LPUSH，消费者 LPOP 对数据进行消费，

     - 数据保序：当 LPUSH 的时候增加一个自定义 ID（需要自己生成）
     - 数据重复：当存在自定 ID 的时候可以通过 ID 来判断是否消费过
     - 数据可靠性：读取数据时将数据写入 MQBACK LIST 进行缓存备份

   - Steams

     生产者 SADD，消费者SREAD 对数据进行消费，同时支持 SREADGROUP 针对消费组

     - 数据保序：可以生成 ID，默认 ID 规则为系统时间戳
     - 数据重复：自动生成唯一 ID
     - 数据可靠性：使用 PENDING LIST 自动留存消息，使用 XACK 确认消息

     ![img](https://static001.geekbang.org/resource/image/b2/14/b2d6581e43f573da6218e790bb8c6814.jpg?wh=2922*943)
   
10. redis 异步执行

   redis 主要阻塞点分为 5 个：

   - 客户端：网络 IO，键值对操作，数据库操作
   - 磁盘：生成 RDB 快照，记录 AOF 日志，AOF 日志重写
   - 主从节点：主库生成、传输 RDB 从库接收 清除数据库加载 RDB 文件
   - 切片集群实例：向其他实例传输哈希槽信息，数据迁移

   ![img](https://static001.geekbang.org/resource/image/6c/22/6ce8abb76b3464afe1c4cb3bbe426922.jpg)

   哪些可以用异步线程做处理，不是关键路径的操作，如删除、清除数据库、AOF 日志同步，Redis 在运行时会创建三个子线程，分别负责 AOF 日志写操作、键值对删除、以及文件关闭的异步执行

   留言收获

   什么时候Redis会真正的异步释放内存？

   lazy free机制：Redis收到键值对删除和清空数据库的指令时，主线线程会把这个操作封装成一个任务，放入任务队列中，然后给客户端返回一个完成信息，但实际上，这个删除还没有执行，需要等待后台子线程从任务队列中读取到这个任务后，才开始实际删除键值对，并释放相应的内存空间。

   但是：lazy-free是4.0新增功能，默认关闭。开启这个配置后， 除了replica-lazy-flush之外，其他情况都只是*可能*去异步释放key的内存，并不是每次必定异步释放内存的。是否会真正异步释放内存，取决于key的类型，编码方式，元素数量，所以 即使开启了lazy-free，String类型的bigkey，在删除时依旧有阻塞主线程的风险
   
11. 处理 redis 变慢

   Check list

   1、使用复杂度过高的命令（例如SORT/SUION/ZUNIONSTORE/KEYS），或一次查询全量数据（例如LRANGE key 0 N，但N很大）

   分析：a) 查看slowlog是否存在这些命令 b) Redis进程CPU使用率是否飙升（聚合运算命令导致）

   解决：a) 不使用复杂度过高的命令，或用其他方式代替实现（放在客户端做） b) 数据尽量分批查询（LRANGE key 0 N，建议N<=100，查询全量数据建议使用HSCAN/SSCAN/ZSCAN）

   2、操作bigkey

   分析：a) slowlog出现很多SET/DELETE变慢命令（bigkey分配内存和释放内存变慢） b) 使用redis-cli -h $host -p $port --bigkeys扫描出很多bigkey

   解决：a) 优化业务，避免存储bigkey b) Redis 4.0+可开启lazy-free机制

   3、大量key集中过期

   分析：a) 业务使用EXPIREAT/PEXPIREAT命令 b) Redis info中的expired_keys指标短期突增

   解决：a) 优化业务，过期增加随机时间，把时间打散，减轻删除过期key的压力 b) 运维层面，监控expired_keys指标，有短期突增及时报警排查

   4、Redis内存达到maxmemory

   分析：a) 实例内存达到maxmemory，且写入量大，淘汰key压力变大 b) Redis info中的evicted_keys指标短期突增

   解决：a) 业务层面，根据情况调整淘汰策略（随机比LRU快） b) 运维层面，监控evicted_keys指标，有短期突增及时报警 c) 集群扩容，多个实例减轻淘汰key的压力

   5、大量短连接请求

   分析：Redis处理大量短连接请求，TCP三次握手和四次挥手也会增加耗时

   解决：使用长连接操作Redis

   6、生成RDB和AOF重写fork耗时严重

   分析：a) Redis变慢只发生在生成RDB和AOF重写期间 b) 实例占用内存越大，fork拷贝内存页表越久 c) Redis info中latest_fork_usec耗时变长

   解决：a) 实例尽量小 b) Redis尽量部署在物理机上 c) 优化备份策略（例如低峰期备份） d) 合理配置repl-backlog和slave client-output-buffer-limit，避免主从全量同步 e) 视情况考虑关闭AOF f) 监控latest_fork_usec耗时是否变长

   7、AOF使用awalys机制

   分析：磁盘IO负载变高

   解决：a) 使用everysec机制 b) 丢失数据不敏感的业务不开启AOF

   8、使用Swap

   分析：a) 所有请求全部开始变慢 b) slowlog大量慢日志 c) 查看Redis进程是否使用到了Swap

   解决：a) 增加机器内存 b) 集群扩容 c) Swap使用时监控报警

   9、进程绑定CPU不合理

   分析：a) Redis进程只绑定一个CPU逻辑核 b) NUMA架构下，网络中断处理程序和Redis进程没有绑定在同一个Socket下

   解决：a) Redis进程绑定多个CPU逻辑核 b) 网络中断处理程序和Redis进程绑定在同一个Socket下

   10、开启透明大页机制

   分析：生成RDB和AOF重写期间，主线程处理写请求耗时变长（拷贝内存副本耗时变长）

   解决：关闭透明大页机制

   11、网卡负载过高

   分析：a) TCP/IP层延迟变大，丢包重传变多 b) 是否存在流量过大的实例占满带宽

   解决：a) 机器网络资源监控，负载过高及时报警 b) 提前规划部署策略，访问量大的实例隔离部署

   总之，Redis的性能与CPU、内存、网络、磁盘都息息相关，任何一处发生问题，都会影响到Redis的性能。

   主要涉及到的包括业务使用层面和运维层面：业务人员需要了解Redis基本的运行原理，使用合理的命令、规避bigke问题和集中过期问题。运维层面需要DBA提前规划好部署策略，预留足够的资源，同时做好监控，这样当发生问题时，能够及时发现并尽快处理。
   
12. Redis 存储碎片化

   分为两个因素

   - 外在因素：为 Redis 存储和删除数据

     ![img](https://static001.geekbang.org/resource/image/4d/b8/4d5265c6a38d1839bf4943918f6b6db8.jpg)

   - 内在因素：系统按规定默认大小分配内存空间，会导致空间利用率低但是减少了分配内存

     解决问题办法：

     info memory 命令是一个好工具，可以帮助你查看碎片率的情况；
      INFO memory
     碎片率阈值是一个好经验，可以帮忙你有效地判断是否要进行碎片清理了；

     - mem_fragmentation_ratio = used_memory_rss/ used_memory
     - used_memory_rss 是操作系统实际分配给 Redis 的物理内存空间，里面就包含了碎片；

     - used_memory 是 Redis 为了保存数据实际申请使用的空间

     内存碎片自动清理是一个好方法，可以避免因为碎片导致 Redis 的内存实际利用率降低，提升成本收益率。

     - config set activedefrag yes

     - active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到 100MB 时，开始清理；

     - active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。（第一个和第二个需要同时满足才会开始清理）

     - active-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展；

     - active-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。

13. Redis 缓存淘汰

   缓存淘汰策略分为 8 种：第一种为不淘汰即写满内存访问报错 (noeviction)，其他七种会进行淘汰：

   ​	volatile 机制会对设置过数据过期时间的数据进行淘汰

   - volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。

   - volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。

   - volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对。

   ​    allkeys 针对所有数据进行淘汰：

   - allkeys-random 策略，从所有键值对中随机选择并删除数据；
   - allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选。
   - allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选。
   
14. Redis 缓存异常

   ![img](https://static001.geekbang.org/resource/image/b5/e1/b5bd931239be18bef24b2ef36c70e9e1.jpg)
   
15. Redis 缓存污染

   使用 LRU 缓存策略，Redis 中的 LRU 策略，会在每个数据对应的 RedisObject 结构体中设置一个 lru 字段，用来记录数据的访问时间戳，在进行数据淘汰时，LRU 策略会在候选数据集中淘汰掉 lru 字段值最小的数据。

   但是如果 LRU 策略在处理扫描式单次查询操作时无法解决缓存污染，因为对大量数据进行一次全量读取，每个数据都会更新 lru 字段。

   LFU 缓存策略优化，LFU 是在 LRU 基础上为每个数据增加了一个计数器，来统计这个数据的访问次数，采用先对比访问次数将最低的数据淘汰出缓存，如果两个数据访问次数相同，LFU 策略再比较访问时效性，把距离上一次访问时间更久的数据淘汰。

   LFU RedisObject 相比 LRU `24 bit lru` 字段，又进一步拆成了两部分，

   - ldt 值：Lou 字段的前 16bit，表示数据的访问时间戳
   - counter 值：lru字段的后 8bit，表示数据的访问次数

   counter 计数规则：每当数据被访问一次时，用计数器当前的值乘以配置项 `lfu_log_factor` 再加 1，再取其倒数，得到一个 p 值然后，把这个 p 值和一个取值访问在 (0,1) 间的随机数 r 值比大小，只有 p 值大于 r 值时计数器才加 1

   ```java
   double r = (double)rand()/RAND_MAX;
   ...
   double p = 1.0/(baseval*server.lfu_log_factor+1);
   if (r < p) counter++;
   ```

   counter 衰减机制：LFU 策略使用衰减因子配置项 `lfu_decay_time` 来控制访问次数的衰减，LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位，然后 LFU 策略再把这个差值除以 `lfu_decay_time` 所得的结果就是要衰减的值

16. Redis 并发操作

   Redis 提供了两种方法，分别是加锁和原子操作

   - 加锁是一种常用的方法，在读取数据前，客户端需要先获取锁，否则就无法进行操作，当一个客户端获取到锁后，就会一直持有这把锁，直到客户端完成数据更新才释放这把锁，但是这会有两个问题：一是，如果加锁操作多会降低系统的并发访问性能；第二是 Redis 客户端需要加锁时，需要用到分布式锁，而分布式锁实现复杂，需要用额外的存储系统来提供加解锁操作

   - 原子操作

     - 把多个操作在 Redis 中实现一个操作，也就是单命令操作

       Redis 提供了 `INCR/DECR` 命令，把这三个操作转变为一个原子操作，

       `INCR/DECR` 命令可以对数据进行增值减值操作，而且本身就是一个单命令操作，在执行的时候本身就具有互斥性。

     - 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本

       但是如果我们需要执行操作不是简单的增减数据，这时候就得使用 Lua 脚本来保证原子性，Redis 会把整个 Lua 脚本作为一个整体执行，在执行的过程中不会被其他命令打断，从而保证了 Lua 脚本的原子性

17. Redis 分布式锁

   分布式锁是由共享存储系统维护的变量，多个客户端可以向共享存储发送命令进行加减锁，Redis 作为一个共享存储系统可以用来实现分布式锁，

   在基于单个 Redis 实例实现分布式锁时，对于加锁操作，我们需要满足三个条件：

   - 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但是需要以原子操作完成，所以我们使用 SET 命令带上 NX 选项来实现加锁；
   - 锁变量需要设置过期时间，以免客户端拿到锁后发生异常导致一直无法释放，所以我们需要在 SET 命令执行时加上 EX/PX 选项;
   - 锁变量的值需要能区分出来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标示客户端

18. Redis ACID

   事务是指对数据进行读写的一系列操作，原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）

   Redis 提供了 MULTI、EXEC 两个命令来完成这三步骤，

   - 第一步，客户端使用一个命令显示的开启一个事务 MULTI
   - 第二步，客户端把操作发送到 Redis 将这些命令暂存到一个命令队列中，并不会执行
   - 第三步，客户端向服务器端发送 EXEC 执行事务提交

   Redis 的事物机制能保证哪些属性

   - 原子性，我们分三种情况来看

     - 在执行 EXEC 命令前，客户端发送的操作命令有错误，在命令入队时就会报错并且记录下这个错误，但是我们还可以继续提交事务，但是当执行时 Redis 就会拒绝执行所有的提交的命令操作，返回事务失败
     -  命令和操作的数据类型不匹配，Redis 实例并没有检查出来，但是在执行事务提交命令以后，Redis 实际执行这些事务操作时，就会报错，不过 Redis 还是会将正确的命令执行，但是 Redis 提供了 DISCARD 命令可以用来主动放弃事务执行，将命令队列清空但是起不到回滚的效果
     - 提交事务时 Redis 发生了宕机，如果 Redis 开启了 AOF 日志，那么只有部分事务操作被记录到了 AOF 日志中，我们可以使用 redis-check-aof 工具检查，将未完成的事务移除掉

   - 一致性

     - 命令入队时就报错，在这种情况下，事务本身就会被放弃执行
     - 命令入队时没报错，实际执行报错，在这种情况下有错误的命令不会被执行，正确的命令可以正常执行
     - EXEC 命令执行时实例发生故障，如果我们没有开启 RDB 或 AOF，那么，实例故障重启后，数据都没有了，数据库是一致的。如果我们使用了 RDB 快照，但是 RDB 快照不会在事务执行时执行，所以不会保存数据到 RDB 快照中，如果我们使用了 AOF 日志，而事务操作还没有被记录到 AOF 日志时实例发生了故障，那么数据是一致的，如果只有部分操作被记录了我们需要使用 redis-check-aof 删除错误的事务
   
   - 隔离性
   
     并发操作在 EXEC 命令前执行，此时，隔离性的保证需要使用 WATCH 机制来实现，否则无法保证
   
     WACTH 机制的作用是，在事务执行前，监控一个或者多个数据的变化情况，当 EXEC 命令执行时，如果数据被修改了就会放弃事务执行，然后客户端可以再次执行事务
     
   - 持久性
   
     因为 Redis 是内存数据库，所以，数据是否持久化保存完全取决于 Redis 的持久化配置模式。如果 Redis 没有使用 RDB 或 AOF，那么事务的持久化属性肯定得不到保证。如果 Redis 使用了 RDB 模式，那么，在一个事务执行后，而下一次的 RDB 快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的。如果 Redis 采用了 AOF 模式，因为 AOF 模式的三种配置选项 no、everysec 和 always 都会存在数据丢失的情况，所以，事务的持久性属性也还是得不到保证。所以，不管 Redis 采用什么持久化模式，事务的持久性属性是得不到保证的。
   
   
   总结：Redis 的事务机制可以保证一致性和隔离性，但是无法保证持久性。不过，因为 Redis 本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、一致性和隔离性这三个属性。