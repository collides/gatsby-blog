---
title: MySQL 总结
date: 2021-08-01
update: 2021-10-10
tags: MySQL
---

1. 一条语句是怎么执行的

   ![img](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)

   - 连接器

     负责跟客户端建立连接，获取权限、维持和管理连接，建立连接后会保持长连接默认是 8 小时自动断开,

     在 MySQL 执行过程中临时使用的内存都是存储在连接对象里的当连接断开才会释放资源

   - 查询缓存

     执行查询请求时会访问内存中的 K/V，如果查询到了直接返回缓存内容，但是缓存是以语句进行缓存的如果发生了数据变化会自动清除缓存如果业务不是经常变动可以使用显式指定缓存 

     mysql> select SQL_CACHE * from T where ID=10；

   - 分析器

     MySQL 先会做词法分析，识别字符串分别是什么代表什么，然后再做语法分析判断是否符合语法规范

   - 优化器

     优化器是在表里有多个索引的时候决定采用哪个索引查语句顺序执行效率更快

   - 执行器

     开始执行的时候先判断是否对该表有权限，查缓存的时候也会做权限校验，如果有权限就会使用指定的引擎接口对表进行查询

     - 调用 InnoDB 引擎接口读表第一行，如果满足条件则记录在结果集中，
     - 调用接口取下一行重复相同的判断
     - 执行期将上述遍历过程中所有满足条件的行组成记录集返回

2. 日志模块

   - InnoDB 引擎的 redo log，redo log 大小是固定的可以配置为一组 4 个文件，每个大小 1GB，从头开始写写到末尾又回到开头循环写

     ![img](https://static001.geekbang.org/resource/image/16/a7/16a7950217b3f0f4ed02db5db59562a7.png)

     如果 write pos，追上 checkpoint 表示写满了，这时候不能再执行新的更新 redo log 会将强制刷盘，redo log 是物理日志记录的是 "在某个数据页上做了什么修改" redo log 日志分为 prepare 和 commit 阶段，提交事务前将日志状态置为 prepare 阶段然后生成这个操作的 binlog 并且将 binlog 写入磁盘，然后引擎执行提交事务，然后将 redo log 改为 commit

   - binLog

     binLog 是 MySQL server 层的归档日志，binLog 是逻辑日志记录的是这个语句的原始逻辑，跟 redo log 区别在于 redo log 是循环写的，binLog 可以追加写入，并不会覆盖以前的日志

   - 二阶段提交

     在两阶段提交时，若 redo log 写入成功，bin log 写入失败，则后续通过 bin log 恢复时，恢复的数据将会缺失一部分。(如 redo log 执行了 update t set status = 1，此时原库的数据 status 已更新为 1，而 bin log 写入失败，没有记录这一操作，后续备份恢复时，其 status = 0，导致数据不一致）。

     若先写入 bin log，当 bin log 写入成功，而 redo log 写入失败时，原库中的 status 仍然是 0 ，但是当通过 bin log 恢复时，其记录的操作是 set status = 1，也会导致数据不一致。

     其核心就是， redo log 记录的，即使异常重启，都会刷新到磁盘，而 bin log 记录的， 则主要用于备份。

3. 事务隔离

   1、事务的特性：原子性、一致性、隔离性、持久性
   2、多事务同时执行的时候，可能会出现的问题：脏读、不可重复读、幻读
   3、事务隔离级别：读未提交、读提交、可重复读、串行化
   4、不同事务隔离级别的区别：

   - 读未提交：一个事务还未提交，它所做的变更就可以被别的事务看到

   - 读提交：一个事务提交之后，它所做的变更才可以被别的事务看到

   - 可重复读：一个事务执行过程中看到的数据是一致的。未提交的更改对其他事务是不可见的

   - 串行化：对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行

   5、配置方法：启动参数 transaction-isolation
   6、事务隔离的实现：每条记录在更新的时候都会同时记录一条回滚操作。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）。
   7、回滚日志什么时候删除？系统会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除。
   8、什么时候不需要了？当系统里么有比这个回滚日志更早的 read-view 的时候。
   9、为什么尽量不要使用长事务。长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。
   10、事务启动方式：一、显式启动事务语句，begin 或者 start transaction,提交 commit，回滚 rollback；二、set autocommit=0，该命令会把这个线程的自动提交关掉。这样只要执行一个 select 语句，事务就启动，并不会自动提交，直到主动执行 commit 或 rollback 或断开连接。
   11、建议使用方法一，如果考虑多一次交互问题，可以使用 commit work and chain 语法。在autocommit=1 的情况下用 begin 显式启动事务，如果执行 commit 则提交事务。如果执行 commit work and chain 则提交事务并自动启动下一个事务。

4. MySQL 索引

   索引用于提高数据查询效率，常见的索引模型有：哈希表、有序数组、搜索树，

   - 哈希表：键 - 值

     把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放到数组的这个位置，如果出现了哈希冲突的情况使用链表来解决重复问题，适用于只有等值查询的场景。

   - 有序数组

     按顺序存储，查询用二分法快速查询时间复杂度是 O(log(N))，有序数组查询效率高，更新效率低，适用于静态存储引擎。

   - 二叉搜索树

     每个节点的左子节点小于父节点，父节点又小于右子节点，查询和更新时间复杂度都为 O(log(N))，数据库存储大多不适合用二叉树，因为树高过高一般使用 N 叉树

     索引类型：主键索引、非主键索引

     主键索引的叶子节点存的是整行的数据（聚簇索引），非主键索引的叶子节点存的是主键的值（二级索引），主键和普通索引的区别：主键索引只要搜索 ID 这个 B+Tree 即可拿到数据，而普通索引会先搜索索引拿到主键值然后回主键树再取一次数据（回表）。

     

     覆盖索引：覆盖索引可以减少因为普通索引上数据不足的情况进行回表的操作，例如：

     ```java
     mysql> create table T (ID int primary key,k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT '',index k(k))engine=InnoDB;
     ```

     select ID from T where k between 3 and 5 这时只需要查寻主键的值而 ID 已经存在在普通索引树上了不需要再回表。

     

     最左前缀原则：MySQL 做词法分析、语法分析的时候是通过建立最左子树来建立语法树的，解析的过程也是从左到右所以遵循最左前缀的原则

     索引下推：Index Condition Pushdown，简称 ICP。 是 MySQL 5.6 版本引入的技术优化。旨在 在“仅能利用最左前缀索的场景”下（而不是能利用全部联合索引），对不在最左前缀索引中的其他联合索引字段加以利用——在遍历索引时，就用这些其他字段进行过滤 (where 条件里的匹配)。过滤会减少遍历索引查出的主键条数，从而减少回表次数，提示整体性能。 ------------------ 如果查询利用到了索引下推 ICP 技术，在 Explain 输出的 Extra 字段中会有 “Using index condition”。即代表本次查询会利用到索引，且会利用到索引下推。 索引下推技术的实现——在遍历索引的那一步，由只传入可以利用到的字段值，改成了多传入下推字段值。

     

     B+Tree 索引树：一个数据页如果满了，按照 B+Tree 算法，新增一个数据页叫做页分裂，会导致性能下降，空间利用率会降低，当相邻的两个数据页利用率很低的时候会做数据页的合并，合并的过程是分裂过程的逆过程。

5. MySQL 锁

   MySQL 里的锁分为：全局锁、表级锁、行级锁

   - 全局锁

     对整个数据库实例加锁，加全局锁的方法：Flush tables with read lock (FTWRL)，这个命令可以 i使整个库处于只读状态，使用该命令之后，DML、DDL 语句等操作都会被阻塞，使用场景：全库逻辑备份，风险：如果在主库备份，备份期间服务不可用、如果在从库备份，备份期间不能执行主库同步的 binlog，导致主从延迟。

   - 表级锁

     MySQL 中表级别锁有两种：一种的表锁，一种是元数据锁 (meta data lock，MDL)，

     表锁的语法是：lock tables ... read/write

     可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放，lock tables 语法除了会限制别的线程读写以外还会限制本线程接下来的操作对象，对于 InnoDB 这种支持行级锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。

     MDL 不需要显式使用，在访问一个表的时候会自动加上，保证读写的正确性，在对一个表做 DML 操作的时候，加 MDL 读锁 当要对表进行 DDL 操作的时候加写锁，读锁之间不互斥，读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性，MDL 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。

   - 行级锁

     MySQL 的行锁是在引擎层由各个引擎实现的，不支持行锁意味着并发控制只能使用表锁，对于这种情况同一张表上任何时刻只能有一个更新在执行，会影响到业务并发度，InnoDB 是支持行锁的这也是 MylSAM 被 InnoDB 替代的原因之一，

     二阶段锁：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了立刻释放，而是等到事务提交后才释放。尽量将容易引起并发度的操作就在合适的位置从而减少一次操作中锁住共享数据的时间，进而提升效率

     死锁：当并发系统中不同线程出现循环资源依赖，涉及到的线程都在等待别的线程释放资源，就会导致这几个线程都进入无限等待的状态。

     解决死锁的两种策略：

     - 直接进入等待，直到超时，通过 innodb_lock_wait_timeout 来设置

     - 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务继续执行，innodb_deadlock_detect 设置为 on，死锁检测是在发生死锁的时候能被快速发现并且处理的，但它由额外的负担，如果一个事务被锁的时候，就要看看它所依赖的线程有没有被锁住，每个新来的被堵住的线程都要判断会不会由于自己的加入导致死锁，复杂度为 O(n)。

       1、如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关闭掉。一般不建议采用
       2、控制并发度，对应相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。
       3、将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。

6. 事务隔离机制

   首先要理清楚事务的启动时机，begin/start transacion 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句才会启动事务，如果想马上启动一个事务可以使用 start transaction with consistent snapshot 这个命令。

   MySQL 中有两个视图概念：

   - 一个是 view，它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果
   - 另一个是 InnoDB 在实现 MVCC 时使用到的一致性视图，即 consstent read view 用于支持 RC(Read committed，读提交) 和 RR(Repeatable Read，可重复读)隔离级别的实现

   快照在 MVCC 里是怎么工作的：在 RR 情况下，事务在启动的时候就拍了一个快照，InnoDB 里面每个事务都有一个唯一的 transaction id，它是在事务开始的时候向 InnoDB 的事务系统申请的，是按照顺序严格递增的，每行数据都是有多个版本的，可以根据当前版本和 undo log 计算出目的版本，在实现上 InnoDB 为每个事务都构造了一个数组，用来保存这个事务启动瞬间启动且未提交的所有事务 ID，数组里事务 ID 最小的值为低水位，当前系统里面已经创建过的事务 ID 的最大值为高水位，这个视图数组和高水位就组成了当前事务的一致性视图，而数据版本的可见性规则，就是基于数据的 row trx_id 和一致性视图的对比结果得到的

   ![img](https://static001.geekbang.org/resource/image/88/5e/882114aaf55861832b4270d44507695e.png)

   - 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
   - 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；
   - 如果落在黄色部分，那就包括两种情况 a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。

   更新逻辑：更新数据都是先读后写的，而这个读，只能读当前值，称为当前读 (current read)，所以 RR 其实为 读隔离。

7. 唯一索引和普通索引
   对于查询过程来说：
   a、普通索引，查到满足条件的第一个记录后，继续查找下一个记录，直到第一个不满足条件的记录
   b、唯一索引，由于索引唯一性，查到第一个满足条件的记录后，停止检索
   但是，两者的性能差距微乎其微。因为InnoDB根据数据页来读写的。
   对于更新过程来说：
   概念：change buffer
   当需要更新一个数据页，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在 change buffer 中。下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中的与这个页有关的操作。

   change buffer 是可以持久化的数据。在内存中有拷贝，也会被写入到磁盘上

   purge: 将 change buffer 中的操作应用到原数据页上，得到最新结果的过程，成为 purge
   访问这个数据页会触发 purge，系统有后台线程定期 purge，在数据库正常关闭的过程中，也会执行 purge

   唯一索引的更新不能使用 change buffer

   change buffer 用的是 buffer pool 里的内存，change buffer的大小，可以通过参数innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

   将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。
   change buffer 因为减少了随机磁盘访问，所以对更新性能的提升很明显。

   change buffer使用场景
   在一个数据页做 purge 之前，change buffer 记录的变更越多，收益就越大。
   对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

   反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer,但之后由于马上要访问这个数据页，会立即触发 purge 过程。
   这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

   索引的选择和实践：
   尽可能使用普通索引。
   redo log 主要节省的是随机写磁盘的IO消耗(转成顺序写)，而 change buffer 主要节省的则是随机读磁盘的IO消耗。

8. MySQL 选错索引

   选错索引可能有两种情况：1.由于索引统计信息不准确，导致判断扫描行树不准确，这种情况可以用 analyze table 来解决 2.由于临时表，排序字段，导致优化器误判，这种情况可以用 force index 来强行指定索引，也可以通过修改语句引导优化器，还可以通过增加或者删除索引绕开这个问题

9. 字符串字段创建索引

   1. 直接创建完整索引，这样可能比较占用空间
   2. 创建前缀索引，节省空间，但是可能增加查询扫描次数，并且不能使用覆盖索引
   3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀区分度不够的问题
   4. 创建 hash 字段索引，查询性能稳定，需要有额外的存储和计算消耗，跟第三种方式一样都不支持范围扫描

10. MySQL 刷脏页

    - 第一种场景，InnoDB 的 redo log 写满了这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写
    - 第二种场景，系统内存不足，需要新的内存页，而内存不够用的时候就需要淘汰一些数据页，空出内存给别的数据页使用，如果淘汰的是脏页，就需要将脏页写到磁盘
    - 第三种场景，系统空闲的时候
    - 第四种场景，系统正常关闭的情况，会把内存中的脏页都 flush 到磁盘上

    对性能的影响：

    - 第一种是 redo log 写满了，要 flush 脏页，这种情况是 InnoDB 要尽量避免的，因为出现这种情况的时候整个系统就不能再接受更新了，所有更新都必须堵住。
    - 第二种是 内存不够用了，要先将脏页写到磁盘，InnoDB 的策略是尽量使用内存，当要读入的数据页没有内存的时候，只能将一个最久不使用的数据页冲内存中 flush 掉，如果一个查询要淘汰的脏页个数太多会导致查询的响应时间明显变长，日志写满，更新全部堵住

    InnoDB 刷脏页的控制策略：使用 innodb_io_capacity 参数，指定磁盘能力，建议设置成磁盘的 IOPS，

    指定刷盘速度，innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%，InnoDB 会跟觉当前脏页的比例假设为 M，算出一个范围在 0 到 100 之间的数字:

    ```java
    F1(M)
    { 
      if M>=innodb_max_dirty_pages_pct then
        return 100; 
      return 100*M/innodb_max_dirty_pages_pct;
    }
    ```

    InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值假设为 N，InnoDB 会根据这个 N 算出 [0, 100] 的数字，这个计算公式可以记为 F2(N)，N越大算出来的值越大

    然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度，也就是说，刷脏页速度适合脏页比例以及redo log 没有被 flush 的长度（或者比例）相关的，而且，脏页比例越大或者没有被 flush 的长度越大，刷脏页速度也就越大。

    

    ![img](https://static001.geekbang.org/resource/image/cc/74/cc44c1d080141aa50df6a91067475374.png)

11. 表数据删除

    表数据存储：表数据信息可以存储在共享表空间里，可可以单独存储在一个以 .ibd 为后缀的文件里，由参数 innodb_file_per_table 来控制，建议作为一个单独的文件来存储容易管理，并且在不需要的时候，使用 drop table 命令也可以直接把对应文件删除，如果存储在共享空间中即使表删除了空间也不会释放。

    表结构信息存储：表结构定义占有的存储空间比较小，在 MySQL 8.0 之前，表结构的定义存在以 .frm 为后缀的文件里，在 MySQL 8.0 之后，则允许把表结构的定义信息存在系统数据表中

    表数据删除：delete 命令其实只把记录的位置，或者数据页标记为了 `可复用`，但磁盘文件大小是不会变的，只是一种逻辑删除，所以物理空间并没有释放，使用重建表，消除表因为大量的逻辑删除产生的空洞：

    1. alert table t engine=InnoDB
    2. optimize table t = recreate + analyze
    3. trutace table = drop + create

    空洞：空洞就是那些被标记可复用但是还没被使用的存储空间，使用插入、修改、删除的时候可能会产生空洞

12. 关于 count(*)

    count(*) 的实现方式：

    - MyISAM 引擎将表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个个数效率很高

    - InnoDB 引擎需要将数据一行一行的从引擎里面读出来然后累计计数

      为什么 InnoDB 不使用缓存，因为即使同一个时刻多个查询，由于 MVCC 的原因返回多少行也是不确定的，这和事务设计有关系，可重复读是它的默认隔离级别，在代码上通过多版本并发控制，每一行记录都要判断是否对这个会话可见，因此只能一行一行判断，在能够用于就算 "基于这个查询" 的表的总行数。

      InnoDB 引擎优化：InnoDB 是索引组织表，主键索引的叶子节点是数据，而普通索引树的叶子节点是主键值，所以普通索引比主键索引树小的多，因此 MySQL 优化器会找到最小的那棵树来遍历，在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。

    区别：

    - MyISAM 表虽然 count(*) 很快，但是不支持事务
    - show table status 命令虽然返回很快，但是不准确
    - InnoDB 会遍历全表，虽然结果准确但是会导致性能问题

    不同 count 用法的区别：

    count() 是一个聚合函数，对于返回的结果集，一行一行判断，如果 count 函数的参数不是 null，累计值就加 1,否则不加，最后返回累计值。

    - count 主键，InnoDB 引擎会遍历整张表，把每一行的 id 值取出来给 server 层，server 层拿到 id 后，判断不是为空的就按行累加。
    - count(1)，InnoDB 引擎遍历整张表，但不取值，server 层对于返回的每一行放一个数字 "1" 进去，判断是不可能为空的，按行累加。
    - count 字段，如果这个字段定义为 not null 的话，一行行从记录里读出字段判断不能为 null，按行累加，如果这个字段定义允许为 null，那么执行的时候判断到有可能为 null，还要把值取出来再判断一下，不是 null 才累加。
    - count *，并不会把全部字段取出来，而是专门做了优化，不取值，按行累加

    按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(*)，所以我建议你，尽量使用 count(\*。

13. MySQL 排序

    1. MySQL会为每个线程分配一个内存（sort_buffer）用于排序该内存大小为 sort_buffer_size

       - 如果排序的数据量小于 sort_buffer_size，排序将会在内存中完成

       - 如果排序数据量很大，内存中无法存下这么多数据，则会使用磁盘临时文件来辅助排序，也称外部排序

       - 在使用外部排序时，MySQL会分成好几份单独的临时文件用来存放排序后的数据，然后在将这些文件合并成一个大文件

    2. MySQL 会通过遍历索引将满足条件的数据读取到 sort_buffer，并且按照排序字段进行快速排序

       - 如果查询的字段不包含在辅助索引中，需要按照辅助索引记录的主键返回聚集索引取出所需字段

       - 该方式会造成随机IO，在 MySQL5.6 提供了 MRR 的机制，会将辅助索引匹配记录的主键取出来在内存中进行排序，然后在回表

       - 按照情况建立联合索引来避免排序所带来的性能损耗，允许的情况下也可以建立覆盖索引来避免回表

       全字段排序

       - 通过索引将所需的字段全部读取到 sort_buffer 中

       - 按照排序字段进行排序

       - 将结果集返回给客户端

         缺点：

          - 造成 sort_buffer 中存放不下很多数据，因为除了排序字段还存放其他字段，对 sort_buffer 的利用效率不高
          - 当所需排序数据量很大时，会有很多的临时文件，排序性能也会很差

          优点：MySQL 认为内存足够大时会优先选择全字段排序，因为这种方式比 rowid 排序避免了一次回表操作

          rowid 排序
          1.通过控制排序的行数据的长度来让 sort_buffer 中尽可能多的存放数据，max_length_for_sort_data
          2.只将需要排序的字段和主键读取到 sort_buffer 中，并按照排序字段进行排序
          3.按照排序后的顺序，取id进行回表取出想要获取的数据
          4.将结果集返回给客户端

          优点：更好的利用内存的 sort_buffer 进行排序操作，尽量减少对磁盘的访问

          缺点：回表的操作是随机 IO，会造成大量的随机读，不一定就比全字段排序减少对磁盘的访问

14. MySQL 随机消息

    - 使用 order by rand()

      假设随机排序取前三个，逻辑为：1. 创建临时表，该临时表采用 memoery 引擎，从表中取出需要的值，对每个需要的值执行 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机数和值分别存入临时表中，此时扫描行数是全表数量。2. 然后对没有索引的临时表进行排序。3. 初始化 sort_buffer 从内存临时表中一行一行取出生成的随机数和位置信息存入 sort_buffer 此时扫描行数为两次全表，根据随机数进行排序。4. 排序完成后取出前三个结果的位置信息，依次到内存临时表取出值返回给客户端 目前扫描行数为（全表 * 2 + 3）

      ![img](https://static001.geekbang.org/resource/image/2a/fc/2abe849faa7dcad0189b61238b849ffc.png)

      position 字段：对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；MEMORY 引擎不是索引组织表。在这个里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。

      内存临时表：如果 tmp_table_size 配置限制了内存临时表大小，超过该限制内存就会转为磁盘临时表

      磁盘临时表：磁盘临时表引擎默认是 InnoDB `internal_tmp_disk_storage_engine` 

      优先队列排序算法：MySQL 5.6 版本引入该算法，假设取三个值最小的 rowId，该算法不需要排序整个表而是对于全表先取前三行构造成一个堆，取下一行对比大小假如比堆里的小就替换掉，可以通过 `filesort_priority_queue_optimization` 来设置

    - 随机排序方法

      取得这个表的主键 id 的最大值 M 和最小值 N，用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N，取不小于 X 的第一个 id 的行。这个方法效率很高，因为取 max 和 min 都不需要扫描索引，但是会有 id 空洞的问题，因为选择不同行的概率不一样不是真正的随机，可以通过对表行数量生成随机数然后取数据。

15. SQL 语句逻辑相同执行慢

    SQL 逻辑相同,性能差异较大的,大概有以下几类:

    - 字段发生了转换，导致本该使用索引而没有用到索引
      1. 条件字段函数操作
      2. 隐式类型转换
      3. 隐式字符编码转换
         (如果驱动表的字符集比被驱动表得字符集小，关联列就能用到索引,如果更大,需要发生隐式编码转换,则不能用到索引,latin<gbk<utf8<utf8mb4)

    - 嵌套循环，驱动表与被驱动表选择错误
      1. 连接列上没有索引，导致大表驱动小表，或者小表驱动大表(但是大表走的是全表扫描) --连接列上建立索引
      2. 连接列上虽然有索引，但是驱动表任然选择错误。--通过 straight_join 强制选择关联表顺序
      3. 子查询导致先执行外表在执行子查询，也是驱动表与被驱动表选择错误。
         --可以考虑把子查询改写为内连接,或者改写内联视图(子查询放在from后组成一个临时表,在于其他表进行关联)
      4. 只需要内连接的语句,但是写成了左连接或者右连接。比如 select * from t left join b on t.id=b.id where b.name='abc' 驱动表被固定,大概率会扫描更多的行,导致效率降低.
         --根据业务情况或sql情况,把左连接或者右连接改写为内连接

    - 索引选择不同,造成性能差异较大
      1.select * from t where aid= and create_name>'' order by id limit 1;
      选择走 id 索引或者选择走 (aid,create_time) 索引，性能差异较大.结果集都有可能不一致
      --这个可以通过where条件过滤的值多少来大概判断,该走哪个索引

    - 其它一些因素
      1.比如之前学习到的是否有MDL X锁
      2.innodb_buffer_pool 设置得太小,innodb_io_capacity 设置得太小,刷脏速度跟不上
      3.是否是对表做了 DML 语句之后,马上做 select,导致 change buffer 收益不高
      4.是否有数据空洞
      5.select 选取的数据是否在 buffer_pool 中
      6.硬件原因,资源抢占
      原因多种多样,还需要慢慢补充。

16. MySQL 判断高可用

    - 使用 select 1 语句

      用 select 1 来判断实际上不能判断主库是否可用，因为如果某个表超过了并发查询限制 select 1 仍然可以执行成功，可以在系统表中设置一个 mysql_health_check 表来监控应用是否可用，但是不能避免如果磁盘写满的情况，因为如果 Binlog 写满磁盘会阻塞更新但并不会阻塞查询，并发查询限制的规则为: 如果开始执行语句并且没有被锁阻塞则并发查询数减1，可以通过 innodb_thread_concurrency 来设置

    - 使用 update 语句

      既然需要做更新需要放一个有意义的字段 如 timestamp 字段，用来表示最后一次查询的时间，但是如果系统为双 Master 的主备切换，主库和备库都需要检查，需要设置一个 server_id 字段来判断是否需要更新给备库，但是如果 CPU 利用率百分百的情况下因为我们只需要执行一个 update 字段的语句可能会执行成功并没有超时会认为主库现在为可用状态，根本原因是我们采用的是外部检测方法会有随机性的问题，外部检测需要轮询来检查所以可能系统出问题了但却需要等下一个轮询才能查出来会导致主备切换延迟。

    - 内部统计

      MySQL 5.6 版本提供了 perfrmance_schema 库，就在 file_summary_by_event_name 表里做了 IO 统计，

      ![img](https://static001.geekbang.org/resource/image/75/dd/752ccfe43b4eab155be17401838c62dd.png)

       图中这一行表示统计的是 redo log 的写入时间，第一列 EVENT_NAME 表示统计的类型。接下来的三组数据，显示的是 redo log 操作的时间统计。第一组五列，是所有 IO 类型的统计。其中，COUNT_STAR 是所有 IO 的总次数，接下来四列是具体的统计项， 单位是皮秒；前缀 SUM、MIN、AVG、MAX，顾名思义指的就是总和、最小值、平均值和最大值。第二组六列，是读操作的统计。最后一列 SUM_NUMBER_OF_BYTES_READ 统计的是，总共从 redo log 里读了多少个字节。第三组六列，统计的是写操作。

      因为我们每次操作数据库都需要统计这些数据，会导致降低数据库性能，所以我们只需要打开自己需要统计的数据。

      例如只打开 redo log 监控

      ```java
      mysql> update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';
      ```

      可以通过 MAX_TIMER 来判断数据库是否可用

      ```java
      mysql> select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') and MAX_TIMER_WAIT>200*1000000000;
      ```

      取到异常后，把之前统计的信息清空掉，再次出现异常就可以加入到监控累计值了。

------------

课程后面的内容与 DBA 日常相关目前先暂不学习当遇到相应场景时再思考