---
title: MySQL 总结
date: 2021-8-1
update: 2021-9-21
tags: MySQL
---

1. 一条语句是怎么执行的

   ![img](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)

   - 连接器

     负责跟客户端建立连接，获取权限、维持和管理连接，建立连接后会保持长连接默认是 8 小时自动断开,

     在 MySQL 执行过程中临时使用的内存都是存储在连接对象里的当连接断开才会释放资源

   - 查询缓存

     执行查询请求时会访问内存中的 K/V，如果查询到了直接返回缓存内容，但是缓存是以语句进行缓存的如果发生了数据变化会自动清除缓存如果业务不是经常变动可以使用显式指定缓存 

     mysql> select SQL_CACHE * from T where ID=10；
     
   - 分析器
   
     MySQL 先会做词法分析，识别字符串分别是什么代表什么，然后再做语法分析判断是否符合语法规范
   
   - 优化器
   
     优化器是在表里有多个索引的时候决定采用哪个索引查语句顺序执行效率更快
   
   - 执行器
   
     开始执行的时候先判断是否对该表有权限，查缓存的时候也会做权限校验，如果有权限就会使用指定的引擎接口对表进行查询
   
     - 调用 InnoDB 引擎接口读表第一行，如果满足条件则记录在结果集中，
     - 调用接口取下一行重复相同的判断
     - 执行期将上述遍历过程中所有满足条件的行组成记录集返回
   
2. 日志模块

   - InnoDB 引擎的 redo log，redo log 大小是固定的可以配置为一组 4 个文件，每个大小 1GB，从头开始写写到末尾又回到开头循环写

     ![img](https://static001.geekbang.org/resource/image/16/a7/16a7950217b3f0f4ed02db5db59562a7.png)

     如果 write pos，追上 checkpoint 表示写满了，这时候不能再执行新的更新 redo log 会将强制刷盘，redo log 是物理日志记录的是 "在某个数据页上做了什么修改" redo log 日志分为 prepare 和 commit 阶段，提交事务前将日志状态置为 prepare 阶段然后生成这个操作的 binlog 并且将 binlog 写入磁盘，然后引擎执行提交事务，然后将 redo log 改为 commit
   
   - binLog
   
     binLog 是 MySQL server 层的归档日志，binLog 是逻辑日志记录的是这个语句的原始逻辑，跟 redo log 区别在于 redo log 是循环写的，binLog 可以追加写入，并不会覆盖以前的日志
   
   - 二阶段提交
   
     在两阶段提交时，若 redo log 写入成功，bin log 写入失败，则后续通过 bin log 恢复时，恢复的数据将会缺失一部分。(如 redo log 执行了 update t set status = 1，此时原库的数据 status 已更新为 1，而 bin log 写入失败，没有记录这一操作，后续备份恢复时，其 status = 0，导致数据不一致）。
   
     若先写入 bin log，当 bin log 写入成功，而 redo log 写入失败时，原库中的 status 仍然是 0 ，但是当通过 bin log 恢复时，其记录的操作是 set status = 1，也会导致数据不一致。
   
     其核心就是， redo log 记录的，即使异常重启，都会刷新到磁盘，而 bin log 记录的， 则主要用于备份。
   
3. 事务隔离

   1、事务的特性：原子性、一致性、隔离性、持久性
   2、多事务同时执行的时候，可能会出现的问题：脏读、不可重复读、幻读
   3、事务隔离级别：读未提交、读提交、可重复读、串行化
   4、不同事务隔离级别的区别：

   - 读未提交：一个事务还未提交，它所做的变更就可以被别的事务看到

   - 读提交：一个事务提交之后，它所做的变更才可以被别的事务看到

   - 可重复读：一个事务执行过程中看到的数据是一致的。未提交的更改对其他事务是不可见的

   - 串行化：对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行

   5、配置方法：启动参数 transaction-isolation
   6、事务隔离的实现：每条记录在更新的时候都会同时记录一条回滚操作。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）。
   7、回滚日志什么时候删除？系统会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除。
   8、什么时候不需要了？当系统里么有比这个回滚日志更早的 read-view 的时候。
   9、为什么尽量不要使用长事务。长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。
   10、事务启动方式：一、显式启动事务语句，begin 或者 start transaction,提交 commit，回滚 rollback；二、set autocommit=0，该命令会把这个线程的自动提交关掉。这样只要执行一个 select 语句，事务就启动，并不会自动提交，直到主动执行 commit 或 rollback 或断开连接。
   11、建议使用方法一，如果考虑多一次交互问题，可以使用 commit work and chain 语法。在autocommit=1 的情况下用 begin 显式启动事务，如果执行 commit 则提交事务。如果执行 commit work and chain 则提交事务并自动启动下一个事务。
   
4. MySQL 索引

   索引用于提高数据查询效率，常见的索引模型有：哈希表、有序数组、搜索树，

   - 哈希表：键 - 值

     把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放到数组的这个位置，如果出现了哈希冲突的情况使用链表来解决重复问题，适用于只有等值查询的场景。
     
   - 有序数组
   
     按顺序存储，查询用二分法快速查询时间复杂度是 O(log(N))，有序数组查询效率高，更新效率低，适用于静态存储引擎。
   
   - 二叉搜索树
   
     每个节点的左子节点小于父节点，父节点又小于右子节点，查询和更新时间复杂度都为 O(log(N))，数据库存储大多不适合用二叉树，因为树高过高一般使用 N 叉树
   
     索引类型：主键索引、非主键索引
   
     主键索引的叶子节点存的是整行的数据（聚簇索引），非主键索引的叶子节点存的是主键的值（二级索引），主键和普通索引的区别：主键索引只要搜索 ID 这个 B+Tree 即可拿到数据，而普通索引会先搜索索引拿到主键值然后回主键树再取一次数据（回表）。
   
     
   
     覆盖索引：覆盖索引可以减少因为普通索引上数据不足的情况进行回表的操作，例如：
   
     ```java
     mysql> create table T (ID int primary key,k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT '',index k(k))engine=InnoDB;
     ```
   
     select ID from T where k between 3 and 5 这时只需要查寻主键的值而 ID 已经存在在普通索引树上了不需要再回表。
   
     
   
     最左前缀原则：MySQL 做词法分析、语法分析的时候是通过建立最左子树来建立语法树的，解析的过程也是从左到右所以遵循最左前缀的原则
   
     索引下推：Index Condition Pushdown，简称 ICP。 是 MySQL 5.6 版本引入的技术优化。旨在 在“仅能利用最左前缀索的场景”下（而不是能利用全部联合索引），对不在最左前缀索引中的其他联合索引字段加以利用——在遍历索引时，就用这些其他字段进行过滤 (where 条件里的匹配)。过滤会减少遍历索引查出的主键条数，从而减少回表次数，提示整体性能。 ------------------ 如果查询利用到了索引下推 ICP 技术，在 Explain 输出的 Extra 字段中会有 “Using index condition”。即代表本次查询会利用到索引，且会利用到索引下推。 索引下推技术的实现——在遍历索引的那一步，由只传入可以利用到的字段值，改成了多传入下推字段值。
   
     
   
     B+Tree 索引树：一个数据页如果满了，按照 B+Tree 算法，新增一个数据页叫做页分裂，会导致性能下降，空间利用率会降低，当相邻的两个数据页利用率很低的时候会做数据页的合并，合并的过程是分裂过程的逆过程。
   
5. MySQL 锁

   MySQL 里的锁分为：全局锁、表级锁、行级锁

   - 全局锁

     对整个数据库实例加锁，加全局锁的方法：Flush tables with read lock (FTWRL)，这个命令可以 i使整个库处于只读状态，使用该命令之后，DML、DDL 语句等操作都会被阻塞，使用场景：全库逻辑备份，风险：如果在主库备份，备份期间服务不可用、如果在从库备份，备份期间不能执行主库同步的 binlog，导致主从延迟。

   - 表级锁

     MySQL 中表级别锁有两种：一种的表锁，一种是元数据锁 (meta data lock，MDL)，

     表锁的语法是：lock tables ... read/write

     可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放，lock tables 语法除了会限制别的线程读写以外还会限制本线程接下来的操作对象，对于 InnoDB 这种支持行级锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。

     MDL 不需要显式使用，在访问一个表的时候会自动加上，保证读写的正确性，在对一个表做 DML 操作的时候，加 MDL 读锁 当要对表进行 DDL 操作的时候加写锁，读锁之间不互斥，读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性，MDL 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。

   - 行级锁

     MySQL 的行锁是在引擎层由各个引擎实现的，不支持行锁意味着并发控制只能使用表锁，对于这种情况同一张表上任何时刻只能有一个更新在执行，会影响到业务并发度，InnoDB 是支持行锁的这也是 MylSAM 被 InnoDB 替代的原因之一，

     二阶段锁：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了立刻释放，而是等到事务提交后才释放。尽量将容易引起并发度的操作就在合适的位置从而减少一次操作中锁住共享数据的时间，进而提升效率

     死锁：当并发系统中不同线程出现循环资源依赖，涉及到的线程都在等待别的线程释放资源，就会导致这几个线程都进入无限等待的状态。

     解决死锁的两种策略：

     - 直接进入等待，直到超时，通过 innodb_lock_wait_timeout 来设置

     - 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务继续执行，innodb_deadlock_detect 设置为 on，死锁检测是在发生死锁的时候能被快速发现并且处理的，但它由额外的负担，如果一个事务被锁的时候，就要看看它所依赖的线程有没有被锁住，每个新来的被堵住的线程都要判断会不会由于自己的加入导致死锁，复杂度为 O(n)。

       1、如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关闭掉。一般不建议采用
       2、控制并发度，对应相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。
       3、将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。
   
6. 事务隔离机制

   首先要理清楚事务的启动时机，begin/start transacion 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句才会启动事务，如果想马上启动一个事务可以使用 start transaction with consistent snapshot 这个命令。

   MySQL 中有两个视图概念：

   - 一个是 view，它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果
   - 另一个是 InnoDB 在实现 MVCC 时使用到的一致性视图，即 consstent read view 用于支持 RC(Read committed，读提交) 和 RR(Repeatable Read，可重复读)隔离级别的实现

   快照在 MVCC 里是怎么工作的：在 RR 情况下，事务在启动的时候就拍了一个快照，InnoDB 里面每个事务都有一个唯一的 transaction id，它是在事务开始的时候向 InnoDB 的事务系统申请的，是按照顺序严格递增的，每行数据都是有多个版本的，可以根据当前版本和 undo log 计算出目的版本，在实现上 InnoDB 为每个事务都构造了一个数组，用来保存这个事务启动瞬间启动且未提交的所有事务 ID，数组里事务 ID 最小的值为低水位，当前系统里面已经创建过的事务 ID 的最大值为高水位，这个视图数组和高水位就组成了当前事务的一致性视图，而数据版本的可见性规则，就是基于数据的 row trx_id 和一致性视图的对比结果得到的

   ![img](https://static001.geekbang.org/resource/image/88/5e/882114aaf55861832b4270d44507695e.png)

   - 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
   - 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；
   - 如果落在黄色部分，那就包括两种情况 a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。

   更新逻辑：更新数据都是先读后写的，而这个读，只能读当前值，称为当前读 (current read)，所以 RR 其实为 读隔离。
   
7. 唯一索引和普通索引
   对于查询过程来说：
   a、普通索引，查到满足条件的第一个记录后，继续查找下一个记录，直到第一个不满足条件的记录
   b、唯一索引，由于索引唯一性，查到第一个满足条件的记录后，停止检索
   但是，两者的性能差距微乎其微。因为InnoDB根据数据页来读写的。
   对于更新过程来说：
   概念：change buffer
   当需要更新一个数据页，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在 change buffer 中。下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中的与这个页有关的操作。

   change buffer 是可以持久化的数据。在内存中有拷贝，也会被写入到磁盘上

   purge: 将 change buffer 中的操作应用到原数据页上，得到最新结果的过程，成为 purge
   访问这个数据页会触发 purge，系统有后台线程定期 purge，在数据库正常关闭的过程中，也会执行 purge

   唯一索引的更新不能使用 change buffer

   change buffer 用的是 buffer pool 里的内存，change buffer的大小，可以通过参数innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

   将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。
   change buffer 因为减少了随机磁盘访问，所以对更新性能的提升很明显。

   change buffer使用场景
   在一个数据页做 purge 之前，change buffer 记录的变更越多，收益就越大。
   对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

   反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer,但之后由于马上要访问这个数据页，会立即触发 purge 过程。
   这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

   索引的选择和实践：
   尽可能使用普通索引。
   redo log 主要节省的是随机写磁盘的IO消耗(转成顺序写)，而 change buffer 主要节省的则是随机读磁盘的IO消耗。

8. MySQL 选错索引

   选错索引可能有两种情况：1.由于索引统计信息不准确，导致判断扫描行树不准确，这种情况可以用 analyze table 来解决 2.由于临时表，排序字段，导致优化器误判，这种情况可以用 force index 来强行指定索引，也可以通过修改语句引导优化器，还可以通过增加或者删除索引绕开这个问题

9. 字符串字段创建索引

   1. 直接创建完整索引，这样可能比较占用空间
   2. 创建前缀索引，节省空间，但是可能增加查询扫描次数，并且不能使用覆盖索引
   3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀区分度不够的问题
   4. 创建 hash 字段索引，查询性能稳定，需要有额外的存储和计算消耗，跟第三种方式一样都不支持范围扫描

10. MySQL 刷脏页

   - 第一种场景，InnoDB 的 redo log 写满了这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写
   - 第二种场景，系统内存不足，需要新的内存页，而内存不够用的时候就需要淘汰一些数据页，空出内存给别的数据页使用，如果淘汰的是脏页，就需要将脏页写到磁盘
   - 第三种场景，系统空闲的时候
   - 第四种场景，系统正常关闭的情况，会把内存中的脏页都 flush 到磁盘上

   对性能的影响：

   - 第一种是 redo log 写满了，要 flush 脏页，这种情况是 InnoDB 要尽量避免的，因为出现这种情况的时候整个系统就不能再接受更新了，所有更新都必须堵住。
   - 第二种是 内存不够用了，要先将脏页写到磁盘，InnoDB 的策略是尽量使用内存，当要读入的数据页没有内存的时候，只能将一个最久不使用的数据页冲内存中 flush 掉，如果一个查询要淘汰的脏页个数太多会导致查询的响应时间明显变长，日志写满，更新全部堵住

   InnoDB 刷脏页的控制策略：使用 innodb_io_capacity 参数，指定磁盘能力，建议设置成磁盘的 IOPS，

   指定刷盘速度，innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%，InnoDB 会跟觉当前脏页的比例假设为 M，算出一个范围在 0 到 100 之间的数字:

   ```java
   F1(M)
   { 
     if M>=innodb_max_dirty_pages_pct then
       return 100; 
     return 100*M/innodb_max_dirty_pages_pct;
   }
   ```

   InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值假设为 N，InnoDB 会根据这个 N 算出 [0, 100] 的数字，这个计算公式可以记为 F2(N)，N越大算出来的值越大

   然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度，也就是说，刷脏页速度适合脏页比例以及redo log 没有被 flush 的长度（或者比例）相关的，而且，脏页比例越大或者没有被 flush 的长度越大，刷脏页速度也就越大。

   

   ![img](https://static001.geekbang.org/resource/image/cc/74/cc44c1d080141aa50df6a91067475374.png)

11. 表数据删除

    表数据存储：表数据信息可以存储在共享表空间里，可可以单独存储在一个以 .ibd 为后缀的文件里，由参数 innodb_file_per_table 来控制，建议作为一个单独的文件来存储容易管理，并且在不需要的时候，使用 drop table 命令也可以直接把对应文件删除，如果存储在共享空间中即使表删除了空间也不会释放。

    表结构信息存储：表结构定义占有的存储空间比较小，在 MySQL 8.0 之前，表结构的定义存在以 .frm 为后缀的文件里，在 MySQL 8.0 之后，则允许把表结构的定义信息存在系统数据表中

    表数据删除：delete 命令其实只把记录的位置，或者数据页标记为了 `可复用`，但磁盘文件大小是不会变的，只是一种逻辑删除，所以物理空间并没有释放，使用重建表，消除表因为大量的逻辑删除产生的空洞：

    1. alert table t engine=InnoDB
    2. optimize table t = recreate + analyze
    3. trutace table = drop + create

    空洞：空洞就是那些被标记可复用但是还没被使用的存储空间，使用插入、修改、删除的时候可能会产生空洞
    
12. 关于 count(*)

    count(*) 的实现方式：

    - MyISAM 引擎将表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个个数效率很高

    - InnoDB 引擎需要将数据一行一行的从引擎里面读出来然后累计计数

      为什么 InnoDB 不使用缓存，因为即使同一个时刻多个查询，由于 MVCC 的原因返回多少行也是不确定的，这和事务设计有关系，可重复读是它的默认隔离级别，在代码上通过多版本并发控制，每一行记录都要判断是否对这个会话可见，因此只能一行一行判断，在能够用于就算 "基于这个查询" 的表的总行数。

      InnoDB 引擎优化：InnoDB 是索引组织表，主键索引的叶子节点是数据，而普通索引树的叶子节点是主键值，所以普通索引比主键索引树小的多，因此 MySQL 优化器会找到最小的那棵树来遍历，在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。

    区别：

    - MyISAM 表虽然 count(*) 很快，但是不支持事务
    - show table status 命令虽然返回很快，但是不准确
    - InnoDB 会遍历全表，虽然结果准确但是会导致性能问题

    不同 count 用法的区别：

    count() 是一个聚合函数，对于返回的结果集，一行一行判断，如果 count 函数的参数不是 null，累计值就加 1,否则不加，最后返回累计值。

    - count 主键，InnoDB 引擎会遍历整张表，把每一行的 id 值取出来给 server 层，server 层拿到 id 后，判断不是为空的就按行累加。
    - count(1)，InnoDB 引擎遍历整张表，但不取值，server 层对于返回的每一行放一个数字 "1" 进去，判断是不可能为空的，按行累加。
    - count 字段，如果这个字段定义为 not null 的话，一行行从记录里读出字段判断不能为 null，按行累加，如果这个字段定义允许为 null，那么执行的时候判断到有可能为 null，还要把值取出来再判断一下，不是 null 才累加。
    - count *，并不会把全部字段取出来，而是专门做了优化，不取值，按行累加

    按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(*)，所以我建议你，尽量使用 count(\*)