{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"\n1. 一条语句是怎么执行的\n\n   ![img](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)\n\n   - 连接器\n\n     负责跟客户端建立连接，获取权限、维持和管理连接，建立连接后会保持长连接默认是 8 小时自动断开,\n\n     在 MySQL 执行过程中临时使用的内存都是存储在连接对象里的当连接断开才会释放资源\n\n   - 查询缓存\n\n     执行查询请求时会访问内存中的 K/V，如果查询到了直接返回缓存内容，但是缓存是以语句进行缓存的如果发生了数据变化会自动清除缓存如果业务不是经常变动可以使用显式指定缓存 \n\n     mysql> select SQL_CACHE * from T where ID=10；\n     \n   - 分析器\n   \n     MySQL 先会做词法分析，识别字符串分别是什么代表什么，然后再做语法分析判断是否符合语法规范\n   \n   - 优化器\n   \n     优化器是在表里有多个索引的时候决定采用哪个索引查语句顺序执行效率更快\n   \n   - 执行器\n   \n     开始执行的时候先判断是否对该表有权限，查缓存的时候也会做权限校验，如果有权限就会使用指定的引擎接口对表进行查询\n   \n     - 调用 InnoDB 引擎接口读表第一行，如果满足条件则记录在结果集中，\n     - 调用接口取下一行重复相同的判断\n     - 执行期将上述遍历过程中所有满足条件的行组成记录集返回\n   \n2. 日志模块\n\n   - InnoDB 引擎的 redo log，redo log 大小是固定的可以配置为一组 4 个文件，每个大小 1GB，从头开始写写到末尾又回到开头循环写\n\n     ![img](https://static001.geekbang.org/resource/image/16/a7/16a7950217b3f0f4ed02db5db59562a7.png)\n\n     如果 write pos，追上 checkpoint 表示写满了，这时候不能再执行新的更新 redo log 会将强制刷盘，redo log 是物理日志记录的是 \"在某个数据页上做了什么修改\" redo log 日志分为 prepare 和 commit 阶段，提交事务前将日志状态置为 prepare 阶段然后生成这个操作的 binlog 并且将 binlog 写入磁盘，然后引擎执行提交事务，然后将 redo log 改为 commit\n   \n   - binLog\n   \n     binLog 是 MySQL server 层的归档日志，binLog 是逻辑日志记录的是这个语句的原始逻辑，跟 redo log 区别在于 redo log 是循环写的，binLog 可以追加写入，并不会覆盖以前的日志\n   \n   - 二阶段提交\n   \n     在两阶段提交时，若 redo log 写入成功，bin log 写入失败，则后续通过 bin log 恢复时，恢复的数据将会缺失一部分。(如 redo log 执行了 update t set status = 1，此时原库的数据 status 已更新为 1，而 bin log 写入失败，没有记录这一操作，后续备份恢复时，其 status = 0，导致数据不一致）。\n   \n     若先写入 bin log，当 bin log 写入成功，而 redo log 写入失败时，原库中的 status 仍然是 0 ，但是当通过 bin log 恢复时，其记录的操作是 set status = 1，也会导致数据不一致。\n   \n     其核心就是， redo log 记录的，即使异常重启，都会刷新到磁盘，而 bin log 记录的， 则主要用于备份。\n   \n3. 事务隔离\n\n   1、事务的特性：原子性、一致性、隔离性、持久性\n   2、多事务同时执行的时候，可能会出现的问题：脏读、不可重复读、幻读\n   3、事务隔离级别：读未提交、读提交、可重复读、串行化\n   4、不同事务隔离级别的区别：\n\n   - 读未提交：一个事务还未提交，它所做的变更就可以被别的事务看到\n\n   - 读提交：一个事务提交之后，它所做的变更才可以被别的事务看到\n\n   - 可重复读：一个事务执行过程中看到的数据是一致的。未提交的更改对其他事务是不可见的\n\n   - 串行化：对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行\n\n   5、配置方法：启动参数 transaction-isolation\n   6、事务隔离的实现：每条记录在更新的时候都会同时记录一条回滚操作。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）。\n   7、回滚日志什么时候删除？系统会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除。\n   8、什么时候不需要了？当系统里么有比这个回滚日志更早的 read-view 的时候。\n   9、为什么尽量不要使用长事务。长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。\n   10、事务启动方式：一、显式启动事务语句，begin 或者 start transaction,提交 commit，回滚 rollback；二、set autocommit=0，该命令会把这个线程的自动提交关掉。这样只要执行一个 select 语句，事务就启动，并不会自动提交，直到主动执行 commit 或 rollback 或断开连接。\n   11、建议使用方法一，如果考虑多一次交互问题，可以使用 commit work and chain 语法。在autocommit=1 的情况下用 begin 显式启动事务，如果执行 commit 则提交事务。如果执行 commit work and chain 则提交事务并自动启动下一个事务。\n   \n4. MySQL 索引\n\n   索引用于提高数据查询效率，常见的索引模型有：哈希表、有序数组、搜索树，\n\n   - 哈希表：键 - 值\n\n     把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放到数组的这个位置，如果出现了哈希冲突的情况使用链表来解决重复问题，适用于只有等值查询的场景。\n     \n   - 有序数组\n   \n     按顺序存储，查询用二分法快速查询时间复杂度是 O(log(N))，有序数组查询效率高，更新效率低，适用于静态存储引擎。\n   \n   - 二叉搜索树\n   \n     每个节点的左子节点小于父节点，父节点又小于右子节点，查询和更新时间复杂度都为 O(log(N))，数据库存储大多不适合用二叉树，因为树高过高一般使用 N 叉树\n   \n     索引类型：主键索引、非主键索引\n   \n     主键索引的叶子节点存的是整行的数据（聚簇索引），非主键索引的叶子节点存的是主键的值（二级索引），主键和普通索引的区别：主键索引只要搜索 ID 这个 B+Tree 即可拿到数据，而普通索引会先搜索索引拿到主键值然后回主键树再取一次数据（回表）。\n   \n     \n   \n     覆盖索引：覆盖索引可以减少因为普通索引上数据不足的情况进行回表的操作，例如：\n   \n     ```java\n     mysql> create table T (ID int primary key,k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT '',index k(k))engine=InnoDB;\n     ```\n   \n     select ID from T where k between 3 and 5 这时只需要查寻主键的值而 ID 已经存在在普通索引树上了不需要再回表。\n   \n     \n   \n     最左前缀原则：MySQL 做词法分析、语法分析的时候是通过建立最左子树来建立语法树的，解析的过程也是从左到右所以遵循最左前缀的原则\n   \n     索引下推：Index Condition Pushdown，简称 ICP。 是 MySQL 5.6 版本引入的技术优化。旨在 在“仅能利用最左前缀索的场景”下（而不是能利用全部联合索引），对不在最左前缀索引中的其他联合索引字段加以利用——在遍历索引时，就用这些其他字段进行过滤 (where 条件里的匹配)。过滤会减少遍历索引查出的主键条数，从而减少回表次数，提示整体性能。 ------------------ 如果查询利用到了索引下推 ICP 技术，在 Explain 输出的 Extra 字段中会有 “Using index condition”。即代表本次查询会利用到索引，且会利用到索引下推。 索引下推技术的实现——在遍历索引的那一步，由只传入可以利用到的字段值，改成了多传入下推字段值。\n   \n     \n   \n     B+Tree 索引树：一个数据页如果满了，按照 B+Tree 算法，新增一个数据页叫做页分裂，会导致性能下降，空间利用率会降低，当相邻的两个数据页利用率很低的时候会做数据页的合并，合并的过程是分裂过程的逆过程。\n   \n5. MySQL 锁\n\n   MySQL 里的锁分为：全局锁、表级锁、行级锁\n\n   - 全局锁\n\n     对整个数据库实例加锁，加全局锁的方法：Flush tables with read lock (FTWRL)，这个命令可以 i使整个库处于只读状态，使用该命令之后，DML、DDL 语句等操作都会被阻塞，使用场景：全库逻辑备份，风险：如果在主库备份，备份期间服务不可用、如果在从库备份，备份期间不能执行主库同步的 binlog，导致主从延迟。\n\n   - 表级锁\n\n     MySQL 中表级别锁有两种：一种的表锁，一种是元数据锁 (meta data lock，MDL)，\n\n     表锁的语法是：lock tables ... read/write\n\n     可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放，lock tables 语法除了会限制别的线程读写以外还会限制本线程接下来的操作对象，对于 InnoDB 这种支持行级锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。\n\n     MDL 不需要显式使用，在访问一个表的时候会自动加上，保证读写的正确性，在对一个表做 DML 操作的时候，加 MDL 读锁 当要对表进行 DDL 操作的时候加写锁，读锁之间不互斥，读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性，MDL 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。\n\n   - 行级锁\n\n     MySQL 的行锁是在引擎层由各个引擎实现的，不支持行锁意味着并发控制只能使用表锁，对于这种情况同一张表上任何时刻只能有一个更新在执行，会影响到业务并发度，InnoDB 是支持行锁的这也是 MylSAM 被 InnoDB 替代的原因之一，\n\n     二阶段锁：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了立刻释放，而是等到事务提交后才释放。尽量将容易引起并发度的操作就在合适的位置从而减少一次操作中锁住共享数据的时间，进而提升效率\n\n     死锁：当并发系统中不同线程出现循环资源依赖，涉及到的线程都在等待别的线程释放资源，就会导致这几个线程都进入无限等待的状态。\n\n     解决死锁的两种策略：\n\n     - 直接进入等待，直到超时，通过 innodb_lock_wait_timeout 来设置\n\n     - 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务继续执行，innodb_deadlock_detect 设置为 on，死锁检测是在发生死锁的时候能被快速发现并且处理的，但它由额外的负担，如果一个事务被锁的时候，就要看看它所依赖的线程有没有被锁住，每个新来的被堵住的线程都要判断会不会由于自己的加入导致死锁，复杂度为 O(n)。\n\n       1、如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关闭掉。一般不建议采用\n       2、控制并发度，对应相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。\n       3、将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。\n   \n6. 事务隔离机制\n\n   首先要理清楚事务的启动时机，begin/start transacion 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句才会启动事务，如果想马上启动一个事务可以使用 start transaction with consistent snapshot 这个命令。\n\n   MySQL 中有两个视图概念：\n\n   - 一个是 view，它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果\n   - 另一个是 InnoDB 在实现 MVCC 时使用到的一致性视图，即 consstent read view 用于支持 RC(Read committed，读提交) 和 RR(Repeatable Read，可重复读)隔离级别的实现\n\n   快照在 MVCC 里是怎么工作的：在 RR 情况下，事务在启动的时候就拍了一个快照，InnoDB 里面每个事务都有一个唯一的 transaction id，它是在事务开始的时候向 InnoDB 的事务系统申请的，是按照顺序严格递增的，每行数据都是有多个版本的，可以根据当前版本和 undo log 计算出目的版本，在实现上 InnoDB 为每个事务都构造了一个数组，用来保存这个事务启动瞬间启动且未提交的所有事务 ID，数组里事务 ID 最小的值为低水位，当前系统里面已经创建过的事务 ID 的最大值为高水位，这个视图数组和高水位就组成了当前事务的一致性视图，而数据版本的可见性规则，就是基于数据的 row trx_id 和一致性视图的对比结果得到的\n\n   ![img](https://static001.geekbang.org/resource/image/88/5e/882114aaf55861832b4270d44507695e.png)\n\n   - 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；\n   - 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；\n   - 如果落在黄色部分，那就包括两种情况 a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。\n\n   更新逻辑：更新数据都是先读后写的，而这个读，只能读当前值，称为当前读 (current read)，所以 RR 其实为 读隔离。","excerpt":"一条语句是怎么执行的 img 连接器  负责跟客户端建立连接，获取权限、维持和管理连接，建立连接后会保持长连接默认是 8 小时自动断开,  在 MySQL 执行过程中临时使用的内存都是存储在连接对象里的当连接断开才会释放资源 查询缓存  执行查询请求时会访问内存中的 K/V，如…","fields":{"slug":"/2021-8-1-MySQL/"},"frontmatter":{"date":"Aug 01, 2021","title":"MySQL 总结","tags":["数据库"],"update":"Sep 12, 2020"}}},{"node":{"rawMarkdownBody":"\n学习使用该博客主题, \b\b用于以后记录日常、学习笔记、遇到的难题\n","excerpt":"学习使用该博客主题, \b\b用于以后记录日常、学习笔记、遇到的难题","fields":{"slug":"/post/"},"frontmatter":{"date":"Oct 14, 2020","title":"One day","tags":["记录"],"update":"Oct 14, 2020"}}},{"node":{"rawMarkdownBody":"\n1. 一个 K/V 数据库包含什么？\n\n   - 访问模块\n     - 动态库访问（动态链接库）\n     - 网络访问框架\n       - Socket Server\n       - 请求解析\n\n   - 数据结构 / 操作模块\n\n     - 字符串\n     - 数组\n     - 链表\n     - List\n     - Hash\n\n   - 索引模块\n\n     索引类型有很多，常见的有哈希表、B tree 、字典树，不同的索引结构在性能、空间消耗、并发控制等方面具有不同特征\n\n   - 存储模块\n\n     - 分配器\n     - 持久化\n\n2. Redis 怎么避免数据丢失\n\n   Redis 避免丢失其中一种方式是采用 AOF (日志)，Redis 会在写指令操作成功后对指令进行记录，格式为指令\n\n   ![img](https://static001.geekbang.org/resource/image/4d/9f/4d120bee623642e75fdf1c0700623a9f.jpg)\n\n   \n\n   操作成功后记录日志不会阻塞指令的执行，但是会影响下一个指令的执行效率，还有一种可能指令操作成功后还没来得及写日志就发生了宕机导致数据丢失，对于这个问题 Redis 提供了三种写回 appendfsync 的参数\n\n   ![img](https://static001.geekbang.org/resource/image/72/f8/72f547f18dbac788c7d11yy167d7ebf8.jpg)\n\n   \n\n   如果日志文件太大了怎么办，Redis 提供了重写机制简单来说，根据当前数据库现状创建一个新的 AOF 文件\n\n   并通过只记录当前数据库最新状态的优化方案进行记录\n\n   ![img](https://static001.geekbang.org/resource/image/65/08/6528c699fdcf40b404af57040bb8d208.jpg)\n\n   什么时候会触发 AOF 重写，\n\n   - 手动触发 `bgrewriteaof`\n   - 自动触发 通过 config 指定相应参数\n     - auto-aof-rewrite-percentage 100  // 比上次重写后的体量增加了100%\n     - auto-aof-rewrite-min-size 64mb // 文件大于 64 MB\n\n   AOF 重写会阻塞线程吗？不会，当发生重写时 Redis 会 fork 出一个 bgrewriteaof 子进程，将主进程的内存页表即虚拟内存与实际内存的映射关系 Copy 到子进程，就可以不阻塞主线程的情况下将数据写入到新的 AOF，\n\n   如果有增量数据进入，主进程会继续将日志写入相应内存缓冲区即写旧文件，并且也会写入到新AOF重写缓冲区\n   \n3. RDB 机制\n\n   Redis 支持将当前数据状态打一份内存快照保存到磁盘中，RDB 是全量内存快照相比较 AOF 恢复数据时需要执行全部的操作指令性能较差而`RDB存储的是压缩后的二进制文件，文件较小，对不同的数据类型有针对性的优化，可以通过解析还原数据`，RDB 不会阻塞主线程因为在执行 RDB 时会 fork 出一个子进程进行执行，但是 fork 的过程还是会阻塞主线程，在做快照的中途如果主线程发生了读操作不会影响执行但是如果写数据会将数据做一份副本，RDB 将写入副本 主线程写入数据\n\n   ![img](https://static001.geekbang.org/resource/image/a2/58/a2e5a3571e200cb771ed8a1cd14d5558.jpg)\n\n   \n\n   关于快照的频率不宜过于频繁虽然子进程不会阻塞主线程，但是 fork 的过程还是会阻塞主线程 而且还会产生其他功耗，但是如果频率过慢就可能发生数据丢失，Redis 4.0 中提出了一个混合使用 AOF 和 RDB 的方法，\n   \n   内存快照在一定时间内执行，将两个快照中间的增量数据操作写入 AOF，即减少了快照开销又节省了 AOF 存储指令数量\n   \n   ![img](https://static001.geekbang.org/resource/image/e4/20/e4c5846616c19fe03dbf528437beb320.jpg)\n   \n4. 主从库如何实现数据\n\n   redis 主从机制采用了读写分离，主库负责接收读写请求，从库负责接收读请求，为保证从库可以正确的响应读请求，主库需要向从库同步数据\n\n   - 亮点1：Redis采用读写分离的好处：避免了加锁，实例间协商是否完成修改等复杂操作\n   - 亮点2：全量同步的发生时机：首次上线 和 从库的环形缓冲区位置标识被覆盖\n\n   - 亮点3：增量同步保障机制依赖于一个特殊的数据结构：环形缓冲区\n\n   - 要点1：首次同步分为三个阶段，①：建立连接，②：同步RDB文件，③：同步增量数据\n\n   - 要点2：全量同步需要主机fork子进程，产生全量RDB文件，并发送，为了减轻主机的压力，从机之间也可用互相同步\n\n   - 要点3：增量同步可以缓解主机全量同步的压力，它需要特殊机制保障：replication buffer，环形缓冲区，master_repl_offset，slave_repl_offset\n\n   - 要点4：从机的同步位置标识，在环形缓冲区被覆盖后，会触发新的一轮全量同步，所repl_backlog_buffer的大小是redis重要的调优参数\n\n   - 要点5：主从同步有三种机制：全量同步，基于长链接的命令传播（在写这个笔记时把它忽略了），增量同步\n\n   - 1，repl_backlog_buffer，是随着主机一起诞生的\n   - 2，主机和所有的clent端（包括从机）都会建立一个对应的buffer\n   - 3，replication buffer是与每个clent端一一对应\n   - 4，redis的所有写命令除了用于长链接广播，还都会写入repl_backlog_buffer\n\n5. 哨兵机制\n\n   哨兵机制提供了三种方式来做主库高可用\n\n   - 周期性监听主从库，判断是否下线\n   - 下线后进行选举主库并切换\n   - 切换成功后发送通知到客户端和从库\n\n   1.周期性的向主从库发送 `ping` 网络请求，如果目的地端恢复`ping` 则证明目的地为上线状态否则标为下线状态，下线状态分 `主观下线` 和 `客观下线` 两种，因为网络通信的不可靠性可能会存在网络拥塞或者目的地端网络压力较大会出现`误判`，为了解决该问题可以部署多个哨兵即哨兵集群，各个烧饼会分别对主库进行网络请求判定是否主观下线 当多数时判定为客观下线进行选举主库\n\n   2.主库选举首先会过滤一遍网络较差的从库 具体怎么判断呢？使用配置项 down-after-milliseconds * 10。其中，down-after-milliseconds 是我们认定主从库断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库，后就可以进行打分选举了可以分为三个阶段：从库优先级、从库复制进度、从库 id 长度。\n\n   - 从库优先级\n\n     用户可以通过 `slave-priority` 配置来提升配置较好的从库，如果没有较高优先级的从库即进入下一个阶段。\n\n   - 从库复制进度\n\n     从库通过 `slave-repl-offset` 进行对比选举最接近 `master-repl-offset` 的从库，如果没有最接近的即进入下一个阶段。\n\n   - 从库 id 长度\n\n     redis 默认规则为选举实例 id 较短的从库。\n\n     我们再回顾下这个流程。首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符合要求的从库，然后，依次按照优先级、复制进度、ID 号大小再对剩余的从库进行打分，只要有得分最高的从库出现，就把它选为新主库。\n   \n   哨兵的运行机制\n   \n   哨兵怎么订阅其他哨兵并组成一个哨兵集群，redis 提供了 pub/sub 的机制，可以向主库建立通信并区分事件类型 如`__sentinel__:hello` 的管道，哨兵可以通过该管道发布自己的 ip、port、id、和订阅该管道消息获取其他哨兵信息并建立连接\n   \n   ![img](https://static001.geekbang.org/resource/image/ca/b1/ca42698128aa4c8a374efbc575ea22b1.jpg)\n   \n   哨兵怎么和从库建立连接呢这是由哨兵向主库发送 `INFO` 指令获取从库列表建立连接\n   \n   ![img](https://static001.geekbang.org/resource/image/88/e0/88fdc68eb94c44efbdf7357260091de0.jpg)\n   \n   哨兵怎么和客户端传递消息呢，也是通过主库 pub/sub 的机制客户端通过订阅不同的管道获取不同的信息\n   \n   ![img](https://static001.geekbang.org/resource/image/4e/25/4e9665694a9565abbce1a63cf111f725.jpg)\n   \n   哨兵是怎么选举出 leader 呢，首先哨兵会判定是否为`客观下线`\n   \n   ![img](https://static001.geekbang.org/resource/image/e0/84/e0832d432c14c98066a94e0ef86af384.jpg)\n   \n   后会进行 leader 选举，机制如下\n   \n   ![img](https://static001.geekbang.org/resource/image/5f/d9/5f6ceeb9337e158cc759e23c0f375fd9.jpg)\n   \n6. 集群方案\n\n   如果数据量很大，有两种解决方案\n\n   - 纵向扩容\n\n     就是增加机器的性能提升内存 cpu 磁盘大小，优点是扩容简单容易，缺点是成本大，数据量大时 RDB fork 比较耗时\n\n   - 横向扩容\n\n     就是增加机器节点组成一个`切片集群`，优点是扩容成本低，缺点是切片集群比较复杂\n\n   什么是切片集群，切片集群会将数据以切片的方式存入各个节点，但是数据是怎么分布的和寻址的呢，\n\n   实际上，切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在 Redis 3.0 之前，官方并没有针对切片集群提供具体的方案。从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则。Redis Cluster 采用哈希槽（Hash Slot）来处理数据与节点之间的关系，一个切片集群有 `16384` 个哈希槽，这些哈希槽类似于数据分区，每个键值都会根据它的 key，被映射到一个哈希槽, \n\n   首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽\n\n   ![img](https://static001.geekbang.org/resource/image/7d/ab/7d070c8b19730b308bfaabbe82c2f1ab.jpg)\n\n   也可以通过手动指定哈希槽分布\n\n   ```bash\n   redis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1\n   redis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3\n   redis-cli -h 172.16.19.5 –p 6379 cluster addslots 4\n   ```\n\n   注意：在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。\n\n   客户端如何确定要访问那个实例获取数据：1从任意个实例获取并缓存在自己本地，2，重定向机制\n\n   重定向机制：客户端访问的实例没有数据，被访问实例响应move命令，告诉客户端指向新的实例地址\n\n   ASK命令：1，表明数据正在迁移 ；2，告知客户端数据所在的实例\n   ASK命令和MOVE命令的区别：\n         \tmove命令是在数据迁移完毕后被响应，客户端会更新本地缓存。\n             ASK命令是在数据迁移中被响应，不会让客户端更新缓存\n   \n7. String 处理\n\n   一，作者讲了什么？\n     Redis的String类型数据结构，及其底层实现\n   二，作者是怎么把这事给说明白的？\n     1，通过一个图片存储的案例，讲通过合理利用Redis的数据结构，降低资源消耗\n\n   三，为了讲明白，作者讲了哪些要点？有哪些亮点？\n   1，亮点1：String类型的数据占用内存，分别是被谁占用了\n   2，亮点2：可以巧妙的利用Redis的底层数据结构特性，降低资源消耗\n   3，要点1： Simple Dynamic String结构体（\n            buf：字节数组，为了表示字节结束，会在结尾增加“\\0”\n            len： 占4个字节，表示buf的已用长度\n            alloc：占4个字节，表示buf实际分配的长度，一般大于len）\n\n   4，要点2： RedisObject 结构体（\n             元数据：8字节（用于记录最后一次访问时间，被引用次数。。。）\n             指针：8字节，指向具体数据类型的实际数据所在 ）\n\n   5，要点3：dicEntry 结构体（\n            key：8个字节指针，指向key\n            value：8个字节指针，指向value\n            next：指向下一个dicEntry）\n   6，要点4：ziplist(压缩列表)（\n            zlbytes：在表头，表示列表长度\n            zltail：在表头，表示列尾偏移量\n            zllen：在表头，表示列表中\n            entry：保存数据对象模型\n            zlend：在表尾，表示列表结束）\n   entry：（\n          prev_len：表示一个entry的长度，有两种取值方式：1字节或5字节。\n              1字节表示一个entry小于254字节，255是zlend的默认值，所以不使用。\n          len：表示自身长度，4字节\n          encodeing：表示编码方式，1字节\n          content：保存实际数据）\n\n   5，要点4：String类型的内存空间消耗\n   ①，保存Long类型时，指针直接保存整数数据值，可以节省空间开销（被称为：int编码）\n   ②，保存字符串，且不大于44字节时，RedisObject的元数据，指针和SDS是连续的，可以避免内存碎片（被称为：embstr编码）\n   ③，当保存的字符串大于44字节时，SDS的数据量变多，Redis会给SDS分配独立的空间，并用指针指向SDS结构（被称为：raw编码）\n   ④，Redis使用一个全局哈希表保存所以键值对，哈希表的每一项都是一个dicEntry，每个dicEntry占用32字节空间\n   ⑤，dicEntry自身24字节，但会占用32字节空间，是因为Redis使用了内存分配库jemalloc。\n             jemalloc在分配内存时，会根据申请的字节数N，找一个比N大，但最接近N的2的幂次数作为分配空间，这样可以减少频繁分配内存的次数\n\n   4，要点5：使用什么数据结构可以节省内存？\n   ①， 压缩列表，是一种非常节省内存的数据结构，因为他使用连续的内存空间保存数据，不需要额外的指针进行连接\n   ②，Redis基于压缩列表实现List，Hash，Sorted Set集合类型，最大的好处是节省了dicEntry开销\n\n   5，要点6：如何使用集合类型保存键值对？\n   ①，Hash类型设置了用压缩列表保存数据时的两个阀值，一旦超过就会将压缩列表转为哈希表，且不可回退\n   ②，hash-max-ziplist-entries：表示用压缩列表保存哈希集合中的最大元素个数\n   ③，hash-max-ziplist-value：表示用压缩列表保存时，哈希集合中单个元素的最大长度\n\n   四，对于作者所讲，我有哪些发散性思考？\n     看了老师讲解，做了笔记，又看了黄建宏写的《Redis 设计与实现》\n   有这样的讲解：\n       当哈希对象可以同时满足以下两个条件时， 哈希对象使用 ziplist 编码：\n   \\1. 哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节；\n   \\2. 哈希对象保存的键值对数量小于 512 个；\n\n8. 统计相关\n\n   - 聚合统计\n\n     案例1. 交集统计\n\n     ​\t\t在记录用户流存量，使用 set 进行记录，用一个 key 记录所有用户，再用另外一个 key 记录每日登录用户，我们只用计算每日用户 Set 和累计用户 Set 的差集就行\n\n     ![img](https://static001.geekbang.org/resource/image/a6/9e/a63dd95d5e44bf538fe960e67761b59e.jpg)\n\n     注意：在数据量很大的情况下取 set 类型交、差、并集的时候可能会阻塞 redis 实例\n\n   - 排序统计\n\n     案例：记录商品用户评论，可以使用 List 来记录因为 List 本身是按下标进行位移排序的每次新增数据将数据 PUSH 到 List 顶部，但是如果是分页的情况下如果新增一条新数据会引发数据错位导致取值数据不一致，可以采用 Sorted List 来保存数据，Sorted List 是按照某一个属性权重进行排序，按照某一个 range 就可以保证数据一致\n\n   - 二值状态统计\n\n     案例：记录用户签到，可以使用 BitMap 来保存数据，BitMap 是用 bit 顺序存放的只有 `0|1` ，BitMap 底层是使用 String 实现的会保存成一个二进制字节数组，BitMap 提供了 COUNT 方法可以很容易记录用户签到量，在统计连续签到时可以采用 BitMap 的按为与操作进行简化数据，将每天签到的 BitMap 按为与后取 1 的数量\n\n   - 基数统计\n\n     案例：记录网页 UV，可以采用 HyperLogLog 来进行记录，HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小\n\n   ![img](https://static001.geekbang.org/resource/image/c0/6e/c0bb35d0d91a62ef4ca1bd939a9b136e.jpg)\n   \n9. 消息队列\n\n   消息队列三个问题，数据时序性、数据重复、数据可靠性\n\n   Redis 有两种方式做消息队列的方式\n\n   - List\n\n     生产者 LPUSH，消费者 LPOP 对数据进行消费，\n\n     - 数据保序：当 LPUSH 的时候增加一个自定义 ID（需要自己生成）\n     - 数据重复：当存在自定 ID 的时候可以通过 ID 来判断是否消费过\n     - 数据可靠性：读取数据时将数据写入 MQBACK LIST 进行缓存备份\n\n   - Steams\n\n     生产者 SADD，消费者SREAD 对数据进行消费，同时支持 SREADGROUP 针对消费组\n\n     - 数据保序：可以生成 ID，默认 ID 规则为系统时间戳\n     - 数据重复：自动生成唯一 ID\n     - 数据可靠性：使用 PENDING LIST 自动留存消息，使用 XACK 确认消息\n\n     ![img](https://static001.geekbang.org/resource/image/b2/14/b2d6581e43f573da6218e790bb8c6814.jpg?wh=2922*943)\n   \n10. redis 异步执行\n\n   redis 主要阻塞点分为 5 个：\n\n   - 客户端：网络 IO，键值对操作，数据库操作\n   - 磁盘：生成 RDB 快照，记录 AOF 日志，AOF 日志重写\n   - 主从节点：主库生成、传输 RDB 从库接收 清除数据库加载 RDB 文件\n   - 切片集群实例：向其他实例传输哈希槽信息，数据迁移\n\n   ![img](https://static001.geekbang.org/resource/image/6c/22/6ce8abb76b3464afe1c4cb3bbe426922.jpg)\n\n   哪些可以用异步线程做处理，不是关键路径的操作，如删除、清除数据库、AOF 日志同步，Redis 在运行时会创建三个子线程，分别负责 AOF 日志写操作、键值对删除、以及文件关闭的异步执行\n\n   留言收获\n\n   什么时候Redis会真正的异步释放内存？\n\n   lazy free机制：Redis收到键值对删除和清空数据库的指令时，主线线程会把这个操作封装成一个任务，放入任务队列中，然后给客户端返回一个完成信息，但实际上，这个删除还没有执行，需要等待后台子线程从任务队列中读取到这个任务后，才开始实际删除键值对，并释放相应的内存空间。\n\n   但是：lazy-free是4.0新增功能，默认关闭。开启这个配置后， 除了replica-lazy-flush之外，其他情况都只是*可能*去异步释放key的内存，并不是每次必定异步释放内存的。是否会真正异步释放内存，取决于key的类型，编码方式，元素数量，所以 即使开启了lazy-free，String类型的bigkey，在删除时依旧有阻塞主线程的风险\n   \n11. 处理 redis 变慢\n\n   Check list\n\n   1、使用复杂度过高的命令（例如SORT/SUION/ZUNIONSTORE/KEYS），或一次查询全量数据（例如LRANGE key 0 N，但N很大）\n\n   分析：a) 查看slowlog是否存在这些命令 b) Redis进程CPU使用率是否飙升（聚合运算命令导致）\n\n   解决：a) 不使用复杂度过高的命令，或用其他方式代替实现（放在客户端做） b) 数据尽量分批查询（LRANGE key 0 N，建议N<=100，查询全量数据建议使用HSCAN/SSCAN/ZSCAN）\n\n   2、操作bigkey\n\n   分析：a) slowlog出现很多SET/DELETE变慢命令（bigkey分配内存和释放内存变慢） b) 使用redis-cli -h $host -p $port --bigkeys扫描出很多bigkey\n\n   解决：a) 优化业务，避免存储bigkey b) Redis 4.0+可开启lazy-free机制\n\n   3、大量key集中过期\n\n   分析：a) 业务使用EXPIREAT/PEXPIREAT命令 b) Redis info中的expired_keys指标短期突增\n\n   解决：a) 优化业务，过期增加随机时间，把时间打散，减轻删除过期key的压力 b) 运维层面，监控expired_keys指标，有短期突增及时报警排查\n\n   4、Redis内存达到maxmemory\n\n   分析：a) 实例内存达到maxmemory，且写入量大，淘汰key压力变大 b) Redis info中的evicted_keys指标短期突增\n\n   解决：a) 业务层面，根据情况调整淘汰策略（随机比LRU快） b) 运维层面，监控evicted_keys指标，有短期突增及时报警 c) 集群扩容，多个实例减轻淘汰key的压力\n\n   5、大量短连接请求\n\n   分析：Redis处理大量短连接请求，TCP三次握手和四次挥手也会增加耗时\n\n   解决：使用长连接操作Redis\n\n   6、生成RDB和AOF重写fork耗时严重\n\n   分析：a) Redis变慢只发生在生成RDB和AOF重写期间 b) 实例占用内存越大，fork拷贝内存页表越久 c) Redis info中latest_fork_usec耗时变长\n\n   解决：a) 实例尽量小 b) Redis尽量部署在物理机上 c) 优化备份策略（例如低峰期备份） d) 合理配置repl-backlog和slave client-output-buffer-limit，避免主从全量同步 e) 视情况考虑关闭AOF f) 监控latest_fork_usec耗时是否变长\n\n   7、AOF使用awalys机制\n\n   分析：磁盘IO负载变高\n\n   解决：a) 使用everysec机制 b) 丢失数据不敏感的业务不开启AOF\n\n   8、使用Swap\n\n   分析：a) 所有请求全部开始变慢 b) slowlog大量慢日志 c) 查看Redis进程是否使用到了Swap\n\n   解决：a) 增加机器内存 b) 集群扩容 c) Swap使用时监控报警\n\n   9、进程绑定CPU不合理\n\n   分析：a) Redis进程只绑定一个CPU逻辑核 b) NUMA架构下，网络中断处理程序和Redis进程没有绑定在同一个Socket下\n\n   解决：a) Redis进程绑定多个CPU逻辑核 b) 网络中断处理程序和Redis进程绑定在同一个Socket下\n\n   10、开启透明大页机制\n\n   分析：生成RDB和AOF重写期间，主线程处理写请求耗时变长（拷贝内存副本耗时变长）\n\n   解决：关闭透明大页机制\n\n   11、网卡负载过高\n\n   分析：a) TCP/IP层延迟变大，丢包重传变多 b) 是否存在流量过大的实例占满带宽\n\n   解决：a) 机器网络资源监控，负载过高及时报警 b) 提前规划部署策略，访问量大的实例隔离部署\n\n   总之，Redis的性能与CPU、内存、网络、磁盘都息息相关，任何一处发生问题，都会影响到Redis的性能。\n\n   主要涉及到的包括业务使用层面和运维层面：业务人员需要了解Redis基本的运行原理，使用合理的命令、规避bigke问题和集中过期问题。运维层面需要DBA提前规划好部署策略，预留足够的资源，同时做好监控，这样当发生问题时，能够及时发现并尽快处理。\n   \n12. Redis 存储碎片化\n\n   分为两个因素\n\n   - 外在因素：为 Redis 存储和删除数据\n\n     ![img](https://static001.geekbang.org/resource/image/4d/b8/4d5265c6a38d1839bf4943918f6b6db8.jpg)\n\n   - 内在因素：系统按规定默认大小分配内存空间，会导致空间利用率低但是减少了分配内存\n\n     解决问题办法：\n\n     info memory 命令是一个好工具，可以帮助你查看碎片率的情况；\n      INFO memory\n     碎片率阈值是一个好经验，可以帮忙你有效地判断是否要进行碎片清理了；\n\n     - mem_fragmentation_ratio = used_memory_rss/ used_memory\n     - used_memory_rss 是操作系统实际分配给 Redis 的物理内存空间，里面就包含了碎片；\n\n     - used_memory 是 Redis 为了保存数据实际申请使用的空间\n\n     内存碎片自动清理是一个好方法，可以避免因为碎片导致 Redis 的内存实际利用率降低，提升成本收益率。\n\n     - config set activedefrag yes\n\n     - active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到 100MB 时，开始清理；\n\n     - active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。（第一个和第二个需要同时满足才会开始清理）\n\n     - active-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展；\n\n     - active-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。\n\n13. Redis 缓存淘汰\n\n   缓存淘汰策略分为 8 种：第一种为不淘汰即写满内存访问报错 (noeviction)，其他七种会进行淘汰：\n\n   ​\tvolatile 机制会对设置过数据过期时间的数据进行淘汰\n\n   - volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。\n\n   - volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。\n\n   - volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对。\n\n   ​    allkeys 针对所有数据进行淘汰：\n\n   - allkeys-random 策略，从所有键值对中随机选择并删除数据；\n   - allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选。\n   - allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选。\n   \n14. Redis 缓存异常\n\n   ![img](https://static001.geekbang.org/resource/image/b5/e1/b5bd931239be18bef24b2ef36c70e9e1.jpg)\n   \n15. Redis 缓存污染\n\n   使用 LRU 缓存策略，Redis 中的 LRU 策略，会在每个数据对应的 RedisObject 结构体中设置一个 lru 字段，用来记录数据的访问时间戳，在进行数据淘汰时，LRU 策略会在候选数据集中淘汰掉 lru 字段值最小的数据。\n\n   但是如果 LRU 策略在处理扫描式单次查询操作时无法解决缓存污染，因为对大量数据进行一次全量读取，每个数据都会更新 lru 字段。\n\n   LFU 缓存策略优化，LFU 是在 LRU 基础上为每个数据增加了一个计数器，来统计这个数据的访问次数，采用先对比访问次数将最低的数据淘汰出缓存，如果两个数据访问次数相同，LFU 策略再比较访问时效性，把距离上一次访问时间更久的数据淘汰。\n\n   LFU RedisObject 相比 LRU `24 bit lru` 字段，又进一步拆成了两部分，\n\n   - ldt 值：Lou 字段的前 16bit，表示数据的访问时间戳\n   - counter 值：lru字段的后 8bit，表示数据的访问次数\n\n   counter 计数规则：每当数据被访问一次时，用计数器当前的值乘以配置项 `lfu_log_factor` 再加 1，再取其倒数，得到一个 p 值然后，把这个 p 值和一个取值访问在 (0,1) 间的随机数 r 值比大小，只有 p 值大于 r 值时计数器才加 1\n\n   ```java\n   double r = (double)rand()/RAND_MAX;\n   ...\n   double p = 1.0/(baseval*server.lfu_log_factor+1);\n   if (r < p) counter++;\n   ```\n\n   counter 衰减机制：LFU 策略使用衰减因子配置项 `lfu_decay_time` 来控制访问次数的衰减，LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位，然后 LFU 策略再把这个差值除以 `lfu_decay_time` 所得的结果就是要衰减的值\n\n16. Redis 并发操作\n\n   Redis 提供了两种方法，分别是加锁和原子操作\n\n   - 加锁是一种常用的方法，在读取数据前，客户端需要先获取锁，否则就无法进行操作，当一个客户端获取到锁后，就会一直持有这把锁，直到客户端完成数据更新才释放这把锁，但是这会有两个问题：一是，如果加锁操作多会降低系统的并发访问性能；第二是 Redis 客户端需要加锁时，需要用到分布式锁，而分布式锁实现复杂，需要用额外的存储系统来提供加解锁操作\n\n   - 原子操作\n\n     - 把多个操作在 Redis 中实现一个操作，也就是单命令操作\n\n       Redis 提供了 `INCR/DECR` 命令，把这三个操作转变为一个原子操作，\n\n       `INCR/DECR` 命令可以对数据进行增值减值操作，而且本身就是一个单命令操作，在执行的时候本身就具有互斥性。\n\n     - 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本\n\n       但是如果我们需要执行操作不是简单的增减数据，这时候就得使用 Lua 脚本来保证原子性，Redis 会把整个 Lua 脚本作为一个整体执行，在执行的过程中不会被其他命令打断，从而保证了 Lua 脚本的原子性\n\n17. Redis 分布式锁\n\n   分布式锁是由共享存储系统维护的变量，多个客户端可以向共享存储发送命令进行加减锁，Redis 作为一个共享存储系统可以用来实现分布式锁，\n\n   在基于单个 Redis 实例实现分布式锁时，对于加锁操作，我们需要满足三个条件：\n\n   - 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但是需要以原子操作完成，所以我们使用 SET 命令带上 NX 选项来实现加锁；\n   - 锁变量需要设置过期时间，以免客户端拿到锁后发生异常导致一直无法释放，所以我们需要在 SET 命令执行时加上 EX/PX 选项;\n   - 锁变量的值需要能区分出来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标示客户端\n\n18. Redis ACID\n\n   事务是指对数据进行读写的一系列操作，原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）\n\n   Redis 提供了 MULTI、EXEC 两个命令来完成这三步骤，\n\n   - 第一步，客户端使用一个命令显示的开启一个事务 MULTI\n   - 第二步，客户端把操作发送到 Redis 将这些命令暂存到一个命令队列中，并不会执行\n   - 第三步，客户端向服务器端发送 EXEC 执行事务提交\n\n   Redis 的事物机制能保证哪些属性\n\n   - 原子性，我们分三种情况来看\n\n     - 在执行 EXEC 命令前，客户端发送的操作命令有错误，在命令入队时就会报错并且记录下这个错误，但是我们还可以继续提交事务，但是当执行时 Redis 就会拒绝执行所有的提交的命令操作，返回事务失败\n     -  命令和操作的数据类型不匹配，Redis 实例并没有检查出来，但是在执行事务提交命令以后，Redis 实际执行这些事务操作时，就会报错，不过 Redis 还是会将正确的命令执行，但是 Redis 提供了 DISCARD 命令可以用来主动放弃事务执行，将命令队列清空但是起不到回滚的效果\n     - 提交事务时 Redis 发生了宕机，如果 Redis 开启了 AOF 日志，那么只有部分事务操作被记录到了 AOF 日志中，我们可以使用 redis-check-aof 工具检查，将未完成的事务移除掉\n\n   - 一致性\n\n     - 命令入队时就报错，在这种情况下，事务本身就会被放弃执行\n     - 命令入队时没报错，实际执行报错，在这种情况下有错误的命令不会被执行，正确的命令可以正常执行\n     - EXEC 命令执行时实例发生故障，如果我们没有开启 RDB 或 AOF，那么，实例故障重启后，数据都没有了，数据库是一致的。如果我们使用了 RDB 快照，但是 RDB 快照不会在事务执行时执行，所以不会保存数据到 RDB 快照中，如果我们使用了 AOF 日志，而事务操作还没有被记录到 AOF 日志时实例发生了故障，那么数据是一致的，如果只有部分操作被记录了我们需要使用 redis-check-aof 删除错误的事务\n   \n   - 隔离性\n   \n     并发操作在 EXEC 命令前执行，此时，隔离性的保证需要使用 WATCH 机制来实现，否则无法保证\n   \n     WACTH 机制的作用是，在事务执行前，监控一个或者多个数据的变化情况，当 EXEC 命令执行时，如果数据被修改了就会放弃事务执行，然后客户端可以再次执行事务\n     \n   - 持久性\n   \n     因为 Redis 是内存数据库，所以，数据是否持久化保存完全取决于 Redis 的持久化配置模式。如果 Redis 没有使用 RDB 或 AOF，那么事务的持久化属性肯定得不到保证。如果 Redis 使用了 RDB 模式，那么，在一个事务执行后，而下一次的 RDB 快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的。如果 Redis 采用了 AOF 模式，因为 AOF 模式的三种配置选项 no、everysec 和 always 都会存在数据丢失的情况，所以，事务的持久性属性也还是得不到保证。所以，不管 Redis 采用什么持久化模式，事务的持久性属性是得不到保证的。\n   \n   \n   总结：Redis 的事务机制可以保证一致性和隔离性，但是无法保证持久性。不过，因为 Redis 本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、一致性和隔离性这三个属性。","excerpt":"一个 K/V 数据库包含什么？ 访问模块 动态库访问（动态链接库） 网络访问框架 Socket Server 请求解析 数据结构 / 操作模块 字符串 数组 链表 List Hash 索引模块  索引类型有很多，常见的有哈希表、B tree 、字典树，不同的索引结构在性能、空间…","fields":{"slug":"/2021-7-1-Redis/"},"frontmatter":{"date":"Jul 01, 2020","title":"Redis 总结","tags":["数据库"],"update":"Jul 20, 2020"}}}]}},"pageContext":{}},"staticQueryHashes":["2027115977","694178885"]}